{"cells":[{"cell_type":"markdown","id":"863526c2","metadata":{"id":"863526c2"},"source":["## Tabular Prediction\n","\n","### Background\n","\n","We are building a patient outcome prediction model based on tabular data inputs. The tabular inputs indicate the patient records are represented by a row stored in a table, e.g.,\n","\n","\n","| uid | age | gender | label |\n","| --- | --- | --- | --- |\n","| 1 | 20 | female | 0\n","| 2 | 32 | male | 1 |\n","\n","each row is a patient and we need to make a prediction for the targeting label taking the input feature `age` and `gender` as the input.\n","\n","In this coding challenge, you will need to finish a complete pipeline for a tabular prediction problem including\n","\n","- data preprocessing\n","\n","- feature engineering\n","\n","- evaluation\n","\n","Related paper:\n","\n","[1] Wang, Z., & Sun, J. (2022). Transtab: Learning transferable tabular transformers across tables. NeurIPS'22. https://arxiv.org/pdf/2205.09328.pdf\n"]},{"cell_type":"markdown","id":"44d3491b","metadata":{"id":"44d3491b"},"source":["### Preparation\n","\n","Please download the raw input data from \n","\n","https://github.com/RyanWangZf/codetest-tabular-prediction-demo-data/blob/main/tabular_patient_data.zip\n","\n","and put it on the path `./tabular_patient_data/data_raw.csv`. All the following steps will be made based on it."]},{"cell_type":"code","source":["# This block is to mount on google drive, please comment or skip it if run on local.\n","from google.colab import drive\n","import os\n","drive.mount('/content/drive', force_remount=True)\n","path = os.getcwd()\n","print(os.listdir(path))\n","os.chdir(\"./drive/MyDrive/Colab Notebooks/tabular_prediction\") \n","!nvidia-smi"],"metadata":{"id":"GHHuuTQYuI1g","executionInfo":{"status":"ok","timestamp":1679840154706,"user_tz":-480,"elapsed":60965,"user":{"displayName":"Xin Xia","userId":"08905681214024585973"}},"outputId":"a154180f-0f26-4af4-bb20-ee5c19f81a28","colab":{"base_uri":"https://localhost:8080/"}},"id":"GHHuuTQYuI1g","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","['.config', 'drive', 'sample_data']\n","Sun Mar 26 14:15:53 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv('./tabular_patient_data/data_raw.csv')"],"metadata":{"id":"rXVgSjJLzbcC","executionInfo":{"status":"ok","timestamp":1679840162788,"user_tz":-480,"elapsed":5,"user":{"displayName":"Xin Xia","userId":"08905681214024585973"}}},"id":"rXVgSjJLzbcC","execution_count":2,"outputs":[]},{"cell_type":"markdown","id":"b9c604a7","metadata":{"id":"b9c604a7"},"source":["### Step I: data preprocessing\n","\n","After reading the data, you need to complete the following steps:\n","\n","- fill NaN values with appropriate techniques considering the feature types.\n","\n","- manually check the data and assign the columns into three different types: `binary`, `numerical`, and `categorical`; save the results in three lists."]},{"cell_type":"code","source":["# Author: Xin Xia\n","# Date: 3/26/2023\n","# The first two lines are used for faster debug, please comment them if needed.\n","import random\n","df = pd.read_csv('./tabular_patient_data/data_raw.csv')  \n","\n","##########################\n","#  Code for NaN Filling  #\n","##########################\n","def check_nan_rows(column, show=False):\n","  \"\"\"\n","    :param column: The input raw column loaded from .csv.\n","    :param show: Default to be False. If need to check the rows with nans, turn it to be True.\n","    :return nan_rows, nan_rows_index: The content and index of rows with NaN values.\n","    Find out which rows have NaN values of a given feature.\n","  \"\"\"\n","  col_value = df[column]\n","  nan_rows = df[col_value.isna()]\n","  nan_rows_index = list(nan_rows.index)\n","  if len(nan_rows) > 0:\n","    print(f\"NaN value(s) found in column: {column}, in row(s): {nan_rows_index}\")\n","  else:\n","    print(f\"No NaN values found in column {column}\")\n","  if show:\n","    show_nan_rows(2)\n","  return nan_rows, nan_rows_index\n","\n","def fill_with_random_values(x):\n","    # return 0\n","    return random.choice([0, 1])\n","\n","def fill_nan(column, show=False):\n","  \"\"\"\n","    :param column: The column with NaN values required to be filled.\n","    :param show: Default to be False. If need to check the filled values, turn it to be True\n","    Fill the NaN values in the given column(AKA: feature), considering the feature types. \n","    For features in the binary list, fill the NaNs with a random value from {0,1}. \n","    For features in the categorical list, fill NaNs with the common value of the column.\n","    For features in the numerical list, fill NaNs with the mean value of the column. \n","  \"\"\"\n","  if column in binary:  # fill NaNs in binary columns with a random value from {0,1}\n","    df[column] = df[column].apply(fill_with_random_values)\n","  elif column in categorical:  # fill NaNs in categorical columns with the common values\n","    column_mode = df[column].mode()[0] \n","    df[column].fillna(column_mode, inplace=True)\n","  else:   # fill NaNs in numerical columns with mean value of the column\n","    column_mean = df[column].mean()\n","    df[column].fillna(column_mean, inplace=True)\n","  if show:\n","    show_filled_value(column)\n","\n","def show_nan_rows(num_row):\n","  print(f\"NaN values exist in these rows, for example:\")\n","  print(nan_rows[:num_row])\n","\n","def show_filled_value(column):\n","  print(f\"NaN values in column: {column} are filled with: \")\n","  print([df[column][i] for i in nan_rows_index])\n","\n","def double_check(df): \n","  \"\"\"\n","    :param df: Modified pandas dataframe of the csv\n","    To double check if all of the NaN values have been filled. If not, print a \n","    summary of NaN values in each column.\n","  \"\"\"\n","  if not df.isna().any().any():\n","    print(\"All NaN Values Have Been Filled!\")\n","  else: \n","    print(f\"NaN Values Still Remain in: {df.isna().sum()}\")\n","\n","\n","# Assign the columns into three different types: binary, numerical, and categorical; save the results in three lists.\n","# \"target_label\" should belong to the binary list from a scientic view, but it wasn't used as a feature in the training progress.\n","binary = ['post-menopause', \n","          'human epidermal growth factor receptor 2 is positive', \n","          'estrogen receptor positive',\n","          'progesterone receptor positive', \n","          'prior hormonal therapy', \n","          'prior chemotherapy',\n","          'biopsy type',\n","          'sentinel node biospy', \n","          'axillary dissection',\n","          'target_label']   \n","numerical = ['number of positive axillary nodes', 'tumor size']\n","categorical = ['race', \n","               'treatment', \n","               'tumor laterality', \n","               'cancer histologic grade']\n","\n","# The main scripts of filling NaN values.\n","for column in df.columns:\n","  nan_rows, nan_rows_index = check_nan_rows(column, show=False)  # Find out which rows have NaN values of this column \n","  if len(nan_rows_index):\n","    fill_nan(column, show=True)  # Fill the NaN values, turn show to True if want to check the filled values\n","  \n","double_check(df)  # Double check"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6xNwYij1gvuN","executionInfo":{"status":"ok","timestamp":1679840192580,"user_tz":-480,"elapsed":28,"user":{"displayName":"Xin Xia","userId":"08905681214024585973"}},"outputId":"ef4955aa-6509-473d-c3e8-37af00ab44d5"},"id":"6xNwYij1gvuN","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["NaN value(s) found in column: race, in row(s): [11, 12, 23, 24, 26, 27, 49, 58, 59, 63, 77, 87, 94, 121, 128, 139, 141, 142, 166, 169, 170, 173, 178, 179, 185, 189, 191, 200, 206, 209, 219, 224, 229, 241, 245, 249, 271, 273, 274, 275, 277, 284, 285, 289, 292, 295, 322, 326, 353, 365, 368, 380, 385, 389, 390, 408, 421, 422, 428, 449, 460, 520, 543, 548, 572, 587, 591, 595, 613, 637, 644, 672, 678, 680, 693, 705, 713, 714, 749, 780, 782, 788, 792, 815, 827, 831, 838, 840, 875, 885, 895, 897, 902, 904, 905, 914, 917, 940, 957, 974, 992, 995]\n","NaN values in column: race are filled with: \n","['White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White', 'White']\n","NaN value(s) found in column: post-menopause, in row(s): [0, 3, 19, 22, 35, 37, 42, 52, 67, 70, 82, 85, 98, 105, 109, 128, 130, 144, 149, 150, 153, 156, 159, 165, 180, 252, 258, 259, 262, 265, 268, 274, 287, 293, 300, 303, 305, 326, 336, 341, 347, 349, 353, 354, 355, 359, 361, 365, 375, 379, 383, 386, 393, 402, 428, 429, 455, 460, 468, 478, 481, 494, 516, 529, 536, 541, 549, 554, 561, 571, 576, 597, 608, 611, 622, 642, 653, 659, 671, 684, 687, 692, 726, 727, 734, 738, 741, 755, 759, 762, 777, 786, 789, 792, 808, 809, 821, 825, 833, 869, 890, 891, 912, 917, 921, 930, 942, 945, 949, 969, 970, 996, 997, 999]\n","NaN values in column: post-menopause are filled with: \n","[0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0]\n","NaN value(s) found in column: human epidermal growth factor receptor 2 is positive, in row(s): [4, 6, 35, 45, 50, 55, 70, 120, 122, 123, 130, 141, 182, 186, 203, 205, 207, 232, 239, 243, 250, 258, 276, 281, 283, 287, 300, 304, 313, 315, 353, 366, 372, 386, 390, 409, 411, 416, 418, 420, 445, 489, 493, 494, 502, 504, 512, 519, 524, 535, 538, 541, 572, 584, 585, 611, 614, 621, 633, 646, 653, 656, 662, 668, 669, 672, 695, 697, 698, 703, 704, 716, 718, 728, 740, 744, 757, 769, 779, 786, 817, 827, 831, 854, 860, 867, 890, 892, 894, 904, 929, 935, 938, 943, 957, 958, 966, 971, 991, 994, 995]\n","NaN values in column: human epidermal growth factor receptor 2 is positive are filled with: \n","[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n","NaN value(s) found in column: treatment, in row(s): [7, 10, 12, 26, 27, 32, 34, 48, 71, 81, 82, 85, 90, 92, 104, 121, 125, 151, 180, 194, 196, 209, 221, 227, 231, 235, 236, 244, 249, 251, 253, 272, 291, 302, 306, 322, 325, 332, 333, 334, 358, 360, 370, 389, 404, 408, 436, 450, 461, 469, 475, 488, 490, 492, 501, 511, 513, 525, 529, 532, 545, 551, 572, 576, 577, 582, 589, 600, 601, 611, 618, 625, 626, 647, 661, 668, 673, 679, 688, 690, 714, 723, 725, 740, 746, 749, 756, 758, 761, 777, 794, 858, 888, 901, 906, 922, 949, 957, 970, 973, 977]\n","NaN values in column: treatment are filled with: \n","['Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab', 'Trastuzumab']\n","NaN value(s) found in column: tumor laterality, in row(s): [24, 37, 47, 72, 81, 88, 91, 101, 104, 113, 115, 127, 147, 158, 159, 164, 214, 223, 237, 249, 267, 271, 288, 297, 301, 302, 316, 329, 344, 352, 365, 379, 395, 426, 427, 428, 429, 472, 474, 485, 487, 505, 514, 516, 518, 521, 522, 534, 535, 553, 567, 571, 573, 580, 601, 606, 630, 642, 643, 654, 660, 661, 672, 673, 676, 677, 681, 683, 685, 692, 716, 722, 723, 725, 731, 759, 787, 790, 792, 803, 805, 825, 836, 840, 845, 887, 888, 911, 939, 943, 945, 948, 949, 953, 954, 958, 979]\n","NaN values in column: tumor laterality are filled with: \n","['right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right', 'right']\n","NaN value(s) found in column: estrogen receptor positive, in row(s): [2, 12, 19, 46, 49, 54, 63, 72, 75, 78, 87, 90, 95, 96, 102, 111, 114, 130, 140, 173, 177, 178, 183, 195, 196, 210, 212, 217, 242, 245, 251, 257, 277, 278, 284, 292, 308, 326, 355, 356, 375, 402, 413, 419, 424, 427, 431, 450, 453, 468, 470, 476, 479, 481, 487, 494, 504, 508, 514, 531, 533, 537, 541, 560, 561, 569, 579, 605, 615, 636, 645, 652, 671, 677, 687, 701, 706, 716, 720, 723, 733, 746, 752, 767, 768, 777, 778, 791, 794, 812, 813, 818, 826, 831, 840, 845, 895, 900, 903, 916, 928, 932, 940, 947, 963, 974, 985, 991, 995]\n","NaN values in column: estrogen receptor positive are filled with: \n","[0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1]\n","NaN value(s) found in column: progesterone receptor positive, in row(s): [10, 50, 53, 69, 88, 93, 118, 124, 151, 153, 161, 180, 187, 194, 198, 222, 224, 235, 238, 240, 245, 256, 264, 287, 326, 340, 345, 348, 352, 367, 376, 381, 408, 440, 452, 468, 472, 473, 504, 508, 513, 522, 548, 562, 575, 579, 589, 592, 594, 606, 609, 614, 615, 626, 627, 628, 632, 634, 676, 683, 687, 694, 705, 731, 741, 744, 749, 752, 759, 763, 778, 794, 797, 809, 813, 817, 819, 820, 829, 841, 843, 848, 857, 860, 862, 868, 869, 882, 899, 932, 941, 946, 970, 974]\n","NaN values in column: progesterone receptor positive are filled with: \n","[1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0]\n","NaN value(s) found in column: cancer histologic grade, in row(s): [36, 38, 55, 60, 71, 80, 81, 97, 137, 151, 162, 167, 176, 181, 186, 190, 195, 196, 204, 254, 261, 309, 313, 315, 328, 331, 345, 353, 367, 368, 387, 392, 393, 403, 411, 414, 416, 433, 439, 461, 462, 484, 485, 493, 498, 506, 512, 531, 536, 540, 552, 557, 576, 600, 605, 608, 614, 636, 638, 647, 657, 667, 678, 682, 696, 708, 725, 727, 731, 740, 742, 749, 753, 765, 767, 786, 804, 805, 820, 824, 840, 846, 852, 853, 866, 870, 872, 881, 882, 905, 912, 915, 917, 930, 932, 939, 960, 961, 989, 992, 995]\n","NaN values in column: cancer histologic grade are filled with: \n","['High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High', 'High']\n","NaN value(s) found in column: prior hormonal therapy, in row(s): [1, 10, 14, 73, 79, 92, 106, 107, 111, 124, 125, 136, 143, 147, 150, 156, 182, 186, 191, 199, 209, 216, 217, 226, 228, 256, 258, 262, 264, 269, 278, 282, 322, 323, 344, 348, 358, 381, 384, 387, 389, 393, 398, 401, 405, 416, 439, 449, 454, 459, 463, 464, 499, 512, 527, 534, 537, 559, 569, 570, 581, 591, 606, 613, 643, 683, 684, 686, 688, 704, 708, 710, 711, 714, 721, 749, 750, 751, 765, 772, 797, 824, 827, 829, 841, 848, 851, 855, 866, 867, 884, 888, 896, 902, 906, 914, 917, 919, 924, 944, 946, 948, 956, 958, 965, 984]\n","NaN values in column: prior hormonal therapy are filled with: \n","[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0]\n","NaN value(s) found in column: prior chemotherapy, in row(s): [3, 16, 36, 41, 47, 60, 63, 67, 86, 88, 94, 116, 121, 149, 151, 157, 169, 175, 190, 192, 195, 210, 211, 215, 217, 220, 222, 235, 238, 248, 278, 288, 303, 306, 307, 346, 358, 361, 379, 391, 403, 404, 409, 426, 442, 453, 454, 468, 469, 495, 497, 499, 518, 567, 568, 574, 584, 586, 592, 593, 598, 601, 613, 617, 651, 652, 662, 667, 680, 697, 731, 733, 752, 754, 784, 792, 796, 799, 810, 813, 824, 831, 836, 838, 842, 852, 892, 899, 932, 934, 935, 952, 956, 969, 992]\n","NaN values in column: prior chemotherapy are filled with: \n","[1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n","NaN value(s) found in column: biopsy type, in row(s): [11, 17, 27, 36, 44, 80, 81, 96, 108, 109, 116, 120, 135, 137, 140, 142, 149, 151, 156, 170, 181, 193, 195, 204, 208, 210, 250, 253, 256, 258, 262, 268, 272, 273, 289, 295, 298, 313, 319, 346, 357, 361, 365, 392, 397, 411, 413, 433, 436, 441, 445, 473, 475, 480, 489, 501, 508, 558, 569, 571, 573, 576, 579, 586, 590, 593, 595, 607, 613, 634, 635, 640, 647, 665, 669, 688, 710, 711, 719, 725, 729, 736, 737, 744, 764, 771, 773, 780, 796, 797, 801, 804, 820, 826, 830, 847, 850, 851, 858, 889, 902, 903, 922, 926, 939, 941, 950, 971]\n","NaN values in column: biopsy type are filled with: \n","[0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n","NaN value(s) found in column: sentinel node biospy, in row(s): [7, 16, 29, 31, 35, 40, 46, 49, 51, 62, 78, 80, 81, 92, 96, 113, 133, 134, 144, 145, 149, 161, 165, 169, 176, 208, 218, 224, 225, 226, 229, 244, 249, 251, 260, 277, 296, 301, 307, 316, 359, 363, 380, 385, 391, 396, 423, 432, 433, 450, 456, 466, 479, 512, 520, 528, 535, 563, 565, 573, 583, 596, 604, 610, 616, 634, 651, 665, 674, 679, 691, 698, 707, 720, 721, 730, 731, 740, 754, 757, 766, 771, 772, 792, 795, 797, 800, 803, 807, 814, 845, 846, 857, 860, 866, 871, 892, 903, 913, 927, 930, 932, 938, 941, 944, 953, 969, 972, 981]\n","NaN values in column: sentinel node biospy are filled with: \n","[1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0]\n","NaN value(s) found in column: axillary dissection, in row(s): [38, 43, 50, 54, 57, 58, 84, 90, 101, 134, 144, 145, 151, 153, 154, 170, 182, 189, 214, 217, 221, 231, 233, 251, 281, 292, 296, 305, 326, 339, 352, 354, 363, 379, 382, 389, 399, 406, 407, 408, 436, 442, 451, 464, 468, 473, 474, 480, 491, 510, 514, 517, 523, 526, 527, 534, 536, 557, 603, 636, 650, 659, 668, 677, 680, 689, 693, 696, 708, 714, 726, 734, 744, 773, 775, 789, 790, 808, 809, 810, 843, 865, 866, 867, 875, 893, 896, 912, 915, 916, 945, 952, 955, 956, 962, 985, 986, 990]\n","NaN values in column: axillary dissection are filled with: \n","[1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1]\n","NaN value(s) found in column: number of positive axillary nodes, in row(s): [2, 19, 37, 40, 48, 54, 55, 56, 63, 68, 72, 78, 88, 116, 122, 124, 128, 144, 158, 165, 172, 185, 188, 211, 234, 237, 260, 274, 280, 283, 286, 296, 302, 318, 325, 330, 332, 333, 338, 341, 346, 355, 365, 373, 381, 385, 386, 426, 427, 428, 430, 431, 441, 442, 444, 449, 451, 467, 483, 500, 509, 512, 523, 524, 533, 537, 545, 558, 577, 584, 604, 606, 609, 627, 686, 712, 715, 726, 739, 755, 757, 768, 774, 782, 792, 795, 805, 807, 818, 824, 826, 835, 839, 845, 860, 861, 862, 869, 870, 881, 882, 887, 898, 910, 917, 933, 947, 951, 965, 970, 974, 988, 990]\n","NaN values in column: number of positive axillary nodes are filled with: \n","[0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168, 0.161217587373168]\n","NaN value(s) found in column: tumor size, in row(s): [2, 24, 27, 37, 43, 44, 65, 76, 80, 86, 94, 99, 114, 115, 120, 127, 138, 147, 150, 164, 177, 184, 186, 192, 202, 215, 219, 226, 235, 236, 247, 250, 256, 263, 287, 293, 299, 301, 312, 314, 326, 333, 336, 341, 348, 355, 360, 377, 390, 393, 398, 404, 405, 423, 433, 434, 451, 452, 454, 463, 473, 497, 529, 532, 535, 542, 543, 562, 573, 587, 592, 605, 608, 612, 654, 655, 670, 678, 679, 705, 713, 716, 717, 753, 762, 767, 776, 786, 819, 835, 857, 873, 881, 886, 913, 931, 939, 944, 948, 950, 952, 981, 982, 989]\n","NaN values in column: tumor size are filled with: \n","[2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983, 2.556998315845983]\n","No NaN values found in column target_label\n","All NaN Values Have Been Filled!\n"]}]},{"cell_type":"markdown","id":"86d5b07f","metadata":{"id":"86d5b07f"},"source":["### Step 2: tabular data captioning\n","\n","In this step, you will need to implement a function that transforms each row of table to its corresponding textual descriptions, e.g., for the tabular data\n","\n","| uid | age | gender | smoking |label |\n","| --- | --- | --- | --- | --- |\n","| 1 | 20 | female | 0 | 1 |\n","| 2 | 32 | male | 1 | 0 |\n","\n","we can obtain two sentences, one for each patient:\n","\n","- ``'age 20; gender female'``\n","\n","- ``'age 32; gender male; smoking'``\n","\n","It should be noted during the processing you will need to consider the feature types. For `numerical` and `categorical` features, we need to concatenate the column names and the cell values; for `binary` features, we only keep the column when its value is `1`. \n"]},{"cell_type":"code","execution_count":5,"id":"e4280136","metadata":{"id":"e4280136","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679840207418,"user_tz":-480,"elapsed":1267,"user":{"displayName":"Xin Xia","userId":"08905681214024585973"}},"outputId":"bc786eb7-348c-48b8-a6c0-4ad5c11bbf11"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                      text_description  target_label\n","0    race White; treatment Trastuzumab; tumor later...             0\n","1    race White; post-menopause; human epidermal gr...             0\n","2    race White; post-menopause; human epidermal gr...             0\n","3    race White; post-menopause; treatment Trastuzu...             0\n","4    race Black or Asia; treatment Trastuzumab; tum...             0\n","..                                                 ...           ...\n","995  race White; treatment Cyclophosphamide and Dox...             1\n","996  race White; post-menopause; human epidermal gr...             0\n","997  race Black or Asia; treatment Cyclophosphamide...             0\n","998  race Black or Asia; human epidermal growth fac...             1\n","999  race Black or Asia; treatment Trastuzumab; tum...             1\n","\n","[1000 rows x 2 columns]\n"]}],"source":["# Author: Xin Xia\n","# Date: 3/26/2023\n","###########################\n","# Tabular Data Captioning #\n","###########################\n","def caption_tabular(df):\n","  \"\"\"\n","  :param df: the input tabular dataframe(preprocessed with filling NaN values)\n","  This function generate text descriptions for each row of a tabular dataframe.\n","  The descriptions depend on the feature types(columns except \"target_label\"): \n","  for numerical and categorical features, concatenate the column names and the \n","  cell values; for binary features, only keep the column when its value is 1. \n","  \"\"\"\n","  text_descriptions = []\n","  features = list(df.columns)\n","  for index, row in df.iterrows():\n","    descriptions = []\n","    for feature in features[:-1]: \n","      if feature in numerical or feature in categorical:\n","        feature_description = feature + \" \"+ str(row[feature])\n","        descriptions.append(feature_description)\n","      elif row[feature]:\n","        feature_description = feature\n","        descriptions.append(feature_description)\n","    text_descriptions.append(\"; \".join(descriptions))\n","  return text_descriptions\n","\n","text_descriptions = caption_tabular(df)\n","df_text = pd.DataFrame(text_descriptions, columns=['text_description'])\n","labels = [int(label) for label in df[\"target_label\"]]\n","df_text[\"target_label\"] = labels\n","print(df_text)"]},{"cell_type":"markdown","id":"32c6f91f","metadata":{"id":"32c6f91f"},"source":["### Step 3: model development\n","\n","In this step, you will need to develop a neural network with an embedding layer and fully-connected layers to make text classification.\n","\n","Consider the captioning of the raw patient record, e.g., ``'age 20; gender female'``, we know the corresponding label is `1`. This reduces to a text classification problem for prediction the patient outcome. \n","\n","Here, we are doing **binary classification**. You can modify the functions of the class `TextMLP` for your task."]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_XmG7mwkkzQ","executionInfo":{"status":"ok","timestamp":1679840224006,"user_tz":-480,"elapsed":10646,"user":{"displayName":"Xin Xia","userId":"08905681214024585973"}},"outputId":"7fe6bd2b-a3f5-4bc6-8b49-1ab99fb36ef7"},"id":"Q_XmG7mwkkzQ","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.3\n"]}]},{"cell_type":"code","execution_count":7,"id":"4daccaea","metadata":{"id":"4daccaea","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["28ad201284324f6fa69e8f46fd57d802","991f5c7261b2494ca2dc05c0390b0200","c9bbc221830542fd804677e1afd4eaf6","83b5afa9302445c185837ef6a3f07542","b8360569f16a4440acebbe18b1f2da32","390e0b617dae4af79c6408d7ffa673a5","ebbe0cd202d344c18991a586862c42c7","1df077a23b404fa6ae71445a9ab455ec","b8956c247e4b4d3c88d4c124a3c19f02","1593e5cb3193447b879f318b4561e40b","e14654f94dfe44dabce02f41090d91e1","0b43b0890d2b4bfb94689fe5f5b808b7","565a9f11608a48469b8dc0a2a00212ee","b751710fd3ff4859a606b96cbd5e7059","812845833d1a494082c14244d69936e8","91624053f30a445f93efc2a6527d6aa8","3481edac68af489ba70db25d421a8d4f","fa407a9110bb473796710abe77c9bf0f","9438945058f84e78abbee93539f634a2","9f66c1c0121f43b2bffc161ffd5cc87e","b2764ee4760946168db9e585dccc1f9e","6ab3f5796e5d4489b0c785b23659fa41"]},"executionInfo":{"status":"ok","timestamp":1679840236813,"user_tz":-480,"elapsed":9193,"user":{"displayName":"Xin Xia","userId":"08905681214024585973"}},"outputId":"276427aa-66e4-4699-9675-4d5b928237ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","###### TextMLP with Unpretrained Embedding Layer ######\n","\n","TextMLP(\n","  (embedding): Embedding(10, 768)\n","  (fc1): Linear(in_features=768, out_features=256, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc2): Linear(in_features=256, out_features=2, bias=True)\n","  (softmax): Softmax(dim=1)\n",")\n","\n","###### TextMLP with Pretrained Embedding Layer ######\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28ad201284324f6fa69e8f46fd57d802"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b43b0890d2b4bfb94689fe5f5b808b7"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["TextMLP(\n","  (embedding): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (fc1): Linear(in_features=768, out_features=256, bias=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc2): Linear(in_features=256, out_features=2, bias=True)\n","  (softmax): Softmax(dim=1)\n",")\n"]}],"source":["# Author: Xin Xia\n","# Date: 3/26/2023\n","import torch\n","from torch import nn\n","from transformers import AutoModel\n","\n","class TextMLP(nn.Module):\n","    def __init__(self, num_classes=2, dropout_rate=0.5, use_pretrained=True, vocab_size = None):\n","        super(TextMLP, self).__init__()\n","        self.num_classes = num_classes  # num_classes is default to 2, for the binary classification task\n","        self.use_pretrained = use_pretrained\n","        if self.use_pretrained:\n","          self.embedding = AutoModel.from_pretrained('bert-base-uncased')\n","        else:\n","          assert vocab_size, \"vocab_size is invalid\"\n","          self.embedding = nn.Embedding(vocab_size, 768)\n","        self.fc1 = nn.Linear(768, 256)\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.fc2 = nn.Linear(256, num_classes)\n","        self.softmax = nn.Softmax(dim=1)\n","        \n","    def forward(self, input_ids, attention_mask):\n","        # The embedding layer, provide two choices, the pretraind one from BERT or the one from scratch\n","        if self.use_pretrained:\n","          x = self.embedding(input_ids=input_ids, attention_mask=attention_mask)[1]\n","        else: \n","          x = torch.mean(self.embedding(input_ids), dim=1)\n","\n","        # The fully-connected layers\n","        x = nn.ReLU()(self.fc1(x))  # ReLU activation function for the first layer\n","        x = self.dropout(x)  # add dropout mechanism to avoid overfitting\n","        x = self.softmax(self.fc2(x))  # softmax activation function for the second layer, best match for classification\n","        return x\n","\n","\n","# Create a TextMLP instance using a unpretrained embedding layer. \n","# Vocab_size is decided by the tokenizer and its vocab, here we use 10 for example\n","model = TextMLP(use_pretrained=False, vocab_size = 10)  \n","print(\"\\n###### TextMLP with Unpretrained Embedding Layer ######\\n\")\n","print(model)\n","\n","# Create a TextMLP instance using a pretrained embedding layer from BERT.\n","print(\"\\n###### TextMLP with Pretrained Embedding Layer ######\\n\") \n","model = TextMLP()  \n","print(model)"]},{"cell_type":"markdown","id":"92154c99","metadata":{"id":"92154c99"},"source":["### Step 4: model training and evaluation"]},{"cell_type":"markdown","id":"a6aca442","metadata":{"id":"a6aca442"},"source":["In this step, you will need to implement the training function of the model `TextMLP` for binary classification. Please complete the full training pipeline, which may include\n","\n","- train/test split\n","\n","- tokenization of the input sentences\n","\n","- training of the model\n","\n","- evaluation of the model's performance on the test set\n","\n","Hint: you use the pretrained tokenizers provided by [`transformers`](https://github.com/huggingface/transformers) to tokenize the input sentences to discrete index, which can be then passed to the embedding layer of your `TextMLP`."]},{"cell_type":"code","source":["# Author: Xin Xia\n","# Date: 3/26/2023\n","import torch\n","from torch.utils.data import DataLoader, RandomSampler\n","from transformers import AutoTokenizer\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns\n","\n","def load_data(tokenizer, dataframe, seed=2, split=0.2):\n","  \"\"\"\n","  :param tokenizer: the loaded tokenizer\n","  :param dataframe: the original dataframe with text descriptions\n","  :param split: the ratio of test data split from the original dataframe, default to be 0.2.\n","  This function first splits the dataframe with text descriptions into training and test set. \n","  Then, texts are encoded with loaded tokenizer. Last, build dataset with tokenized text. \n","  \"\"\"\n","  train_split, test_split = train_test_split(dataframe, test_size=split, random_state=seed)\n","  train_texts, train_labels = train_split['text_description'].tolist(), train_split['target_label'].tolist()\n","  test_texts, test_labels = test_split['text_description'].tolist(), test_split['target_label'].tolist()\n","  train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n","  test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n","  train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_encodings['input_ids']),\n","                                                  torch.tensor(train_encodings['attention_mask']),\n","                                                  torch.tensor(train_labels))\n","  test_dataset = torch.utils.data.TensorDataset(torch.tensor(test_encodings['input_ids']),\n","                                                torch.tensor(test_encodings['attention_mask']),\n","                                                torch.tensor(test_labels))\n","  return train_dataset, test_dataset\n","\n","def select_embedding_layer(use_pretrained):\n","  if not use_pretrained:\n","    model = TextMLP(use_pretrained = use_pretrained, vocab_size = tokenizer.vocab_size).to(device)\n","  else: \n","    model = TextMLP().to(device)\n","  return model\n","\n","def smooth(d, rolling_intv):\n","    df = pd.DataFrame(d)\n","    d = list(np.hstack(df.rolling(rolling_intv, min_periods=1).mean().values))\n","    return d\n","\n","def tensor_to_list(loss_list):\n","  loss_list_copy = []\n","  for i in range(len(loss_list)):\n","    loss_list_copy.append(loss_list[i].item())\n","  return loss_list_copy\n","    \n","def plot_loss(loss_list, use_pretrained):\n","  if use_pretrained:\n","    preorun = \"Pretrained\"\n","  else:\n","    preorun = \"Unpretrained\"\n","  steps = list(range(len(loss_list)))\n","  loss_list_copy = tensor_to_list(loss_list)\n","  loss_list_copy_smooth = smooth(loss_list_copy, 100)\n","  plt.figure()\n","  plt.plot(steps, loss_list_copy, '-', color='red', alpha=0.2)\n","  plt.plot(steps, loss_list_copy_smooth, '-', color='red')\n","  plt.xlabel('steps')\n","  plt.ylabel('training loss')\n","  plt.title(f'TextMLP with {preorun} Embedding Layer')\n","  plt.grid(True, linestyle=':', alpha=0.8)\n","  plt.show()\n","\n","def train_model(model, loss_function, optimizer, train_dataset, num_epochs, device, batch_size):\n","  train_data = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n","  loss_list = []\n","  for epoch in range(num_epochs):\n","    with tqdm(total=int(len(train_data)), desc = \"epoch%d\"%epoch) as pbar:\n","      running_loss = 0.0\n","      running_corrects = 0.0\n","      model.train()\n","      for batch in train_data:\n","        input_ids = batch[0].to(device)\n","        attention_mask = batch[1].to(device)\n","        labels = batch[2].to(device)\n","        optimizer.zero_grad()\n","        outputs = model(input_ids, attention_mask)\n","        _, preds = torch.max(outputs, 1)\n","        loss = loss_function(outputs, labels)\n","        loss_list.append(loss)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item() * input_ids.size(0)\n","        running_corrects += torch.sum(preds == labels.data)\n","        pbar.update(1)\n","      epoch_loss = running_loss / len(train_data.dataset)\n","      epoch_acc = running_corrects.double() / len(train_data.dataset)\n","      print('Epoch {}/{} \\nTrain Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs, epoch_loss, epoch_acc))\n","  return model, loss_list\n","\n","def evaluate(model, loss_function, optimizer, test_dataset, num_epochs, device, batch_size): \n","  test_data = DataLoader(test_dataset, sampler=RandomSampler(test_dataset), batch_size=batch_size) \n","  for epoch in range(num_epochs):    \n","    with tqdm(total=int(len(test_data))) as pbar: \n","      model.eval()\n","      running_loss = 0.0\n","      running_corrects = 0.0\n","      for batch in test_data:\n","        input_ids = batch[0].to(device)\n","        attention_mask = batch[1].to(device)\n","        labels = batch[2].to(device)\n","\n","        outputs = model(input_ids, attention_mask)\n","        _, preds = torch.max(outputs, 1)\n","        loss = loss_function(outputs, labels)\n","        running_loss += loss.item() * input_ids.size(0)\n","        running_corrects += torch.sum(preds == labels.data)\n","        pbar.update(1)\n","      epoch_loss = running_loss / len(test_data.dataset)\n","      epoch_acc = running_corrects.double() / len(test_data.dataset)\n","      print('Val Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n","\n","\n","# Hyper parameters for training and test\n","batch_size = 4\n","learning_rate = 1e-6\n","num_epochs = 50\n","loss_function = torch.nn.CrossEntropyLoss()  # loss function used in model training \n","\n","# Specify the device(cuda or cpu) and tokenizer\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")  # load the pretrained tokenizer of BERT\n","\n","# Load the training and test data\n","seed = 4\n","train_dataset, test_dataset = load_data(tokenizer, df_text, seed = seed, split=0.2)"],"metadata":{"id":"Wh-3S7cRb7V2","executionInfo":{"status":"ok","timestamp":1679840469979,"user_tz":-480,"elapsed":2050,"user":{"displayName":"Xin Xia","userId":"08905681214024585973"}}},"id":"Wh-3S7cRb7V2","execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Author: Xin Xia\n","# Date: 3/26/2023\n","##################################\n","# Use Pretrained Embedding Layer #\n","##################################\n","# Load the training and test data\n","use_pretrained = True  # the flag that controls if the model uses an pretrained embedding layer from BERT or not\n","model = select_embedding_layer(use_pretrained) # Create the model instance from TextMLP() object\n","optimizer = torch.optim.AdamW(model.parameters(), lr= learning_rate)  # optimizer used in model training \n","print(\"\\n####### Training a Model with Pretrained Embedding Layer ######\\n\")\n","\n","# model training \n","trained_model, loss_list_pre = train_model(model, loss_function, optimizer, train_dataset, num_epochs, device, batch_size)\n","# evaluation \n","evaluate(trained_model, loss_function, optimizer, test_dataset, 1, device, batch_size)\n","# training loss\n","plot_loss(loss_list_pre, use_pretrained)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"gpNUsz567zNH","executionInfo":{"status":"ok","timestamp":1679841723718,"user_tz":-480,"elapsed":1247897,"user":{"displayName":"Xin Xia","userId":"08905681214024585973"}},"outputId":"67c81ed5-a340-4e06-c156-08c425de0079"},"id":"gpNUsz567zNH","execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["\n","####### Training a Model with Pretrained Embedding Layer ######\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch0: 100%|██████████| 200/200 [00:24<00:00,  8.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50 \n","Train Loss: 0.6086 Acc: 0.7575\n"]},{"output_type":"stream","name":"stderr","text":["epoch1: 100%|██████████| 200/200 [00:25<00:00,  7.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/50 \n","Train Loss: 0.5249 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch2: 100%|██████████| 200/200 [00:24<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/50 \n","Train Loss: 0.5018 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch3: 100%|██████████| 200/200 [00:24<00:00,  8.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/50 \n","Train Loss: 0.4903 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch4: 100%|██████████| 200/200 [00:24<00:00,  8.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/50 \n","Train Loss: 0.4827 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch5: 100%|██████████| 200/200 [00:25<00:00,  7.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/50 \n","Train Loss: 0.4783 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch6: 100%|██████████| 200/200 [00:25<00:00,  7.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/50 \n","Train Loss: 0.4743 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch7: 100%|██████████| 200/200 [00:25<00:00,  7.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/50 \n","Train Loss: 0.4722 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch8: 100%|██████████| 200/200 [00:25<00:00,  7.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/50 \n","Train Loss: 0.4698 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch9: 100%|██████████| 200/200 [00:25<00:00,  7.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/50 \n","Train Loss: 0.4690 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch10: 100%|██████████| 200/200 [00:25<00:00,  7.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11/50 \n","Train Loss: 0.4674 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch11: 100%|██████████| 200/200 [00:24<00:00,  8.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12/50 \n","Train Loss: 0.4664 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch12: 100%|██████████| 200/200 [00:26<00:00,  7.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13/50 \n","Train Loss: 0.4651 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch13: 100%|██████████| 200/200 [00:24<00:00,  8.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14/50 \n","Train Loss: 0.4648 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch14: 100%|██████████| 200/200 [00:24<00:00,  8.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15/50 \n","Train Loss: 0.4646 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch15: 100%|██████████| 200/200 [00:24<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16/50 \n","Train Loss: 0.4632 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch16: 100%|██████████| 200/200 [00:24<00:00,  8.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17/50 \n","Train Loss: 0.4631 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch17: 100%|██████████| 200/200 [00:24<00:00,  8.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18/50 \n","Train Loss: 0.4627 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch18: 100%|██████████| 200/200 [00:24<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19/50 \n","Train Loss: 0.4625 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch19: 100%|██████████| 200/200 [00:24<00:00,  8.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20/50 \n","Train Loss: 0.4620 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch20: 100%|██████████| 200/200 [00:25<00:00,  7.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21/50 \n","Train Loss: 0.4615 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch21: 100%|██████████| 200/200 [00:24<00:00,  8.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22/50 \n","Train Loss: 0.4613 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch22: 100%|██████████| 200/200 [00:24<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23/50 \n","Train Loss: 0.4613 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch23: 100%|██████████| 200/200 [00:24<00:00,  8.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24/50 \n","Train Loss: 0.4613 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch24: 100%|██████████| 200/200 [00:24<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25/50 \n","Train Loss: 0.4611 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch25: 100%|██████████| 200/200 [00:24<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26/50 \n","Train Loss: 0.4610 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch26: 100%|██████████| 200/200 [00:24<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27/50 \n","Train Loss: 0.4608 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch27: 100%|██████████| 200/200 [00:24<00:00,  8.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28/50 \n","Train Loss: 0.4607 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch28: 100%|██████████| 200/200 [00:24<00:00,  8.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29/50 \n","Train Loss: 0.4604 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch29: 100%|██████████| 200/200 [00:24<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30/50 \n","Train Loss: 0.4605 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch30: 100%|██████████| 200/200 [00:24<00:00,  8.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31/50 \n","Train Loss: 0.4603 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch31: 100%|██████████| 200/200 [00:24<00:00,  8.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32/50 \n","Train Loss: 0.4603 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch32: 100%|██████████| 200/200 [00:24<00:00,  8.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33/50 \n","Train Loss: 0.4603 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch33: 100%|██████████| 200/200 [00:24<00:00,  8.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34/50 \n","Train Loss: 0.4601 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch34: 100%|██████████| 200/200 [00:24<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35/50 \n","Train Loss: 0.4600 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch35: 100%|██████████| 200/200 [00:24<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36/50 \n","Train Loss: 0.4600 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch36: 100%|██████████| 200/200 [00:24<00:00,  8.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37/50 \n","Train Loss: 0.4600 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch37: 100%|██████████| 200/200 [00:24<00:00,  8.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38/50 \n","Train Loss: 0.4599 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch38: 100%|██████████| 200/200 [00:24<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39/50 \n","Train Loss: 0.4599 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch39: 100%|██████████| 200/200 [00:24<00:00,  8.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40/50 \n","Train Loss: 0.4599 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch40: 100%|██████████| 200/200 [00:24<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41/50 \n","Train Loss: 0.4599 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch41: 100%|██████████| 200/200 [00:24<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42/50 \n","Train Loss: 0.4598 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch42: 100%|██████████| 200/200 [00:24<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43/50 \n","Train Loss: 0.4598 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch43: 100%|██████████| 200/200 [00:24<00:00,  8.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44/50 \n","Train Loss: 0.4598 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch44: 100%|██████████| 200/200 [00:24<00:00,  8.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45/50 \n","Train Loss: 0.4598 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch45: 100%|██████████| 200/200 [00:24<00:00,  8.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46/50 \n","Train Loss: 0.4597 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch46: 100%|██████████| 200/200 [00:24<00:00,  8.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47/50 \n","Train Loss: 0.4597 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch47: 100%|██████████| 200/200 [00:24<00:00,  8.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48/50 \n","Train Loss: 0.4597 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch48: 100%|██████████| 200/200 [00:24<00:00,  8.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49/50 \n","Train Loss: 0.4597 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch49: 100%|██████████| 200/200 [00:24<00:00,  8.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50/50 \n","Train Loss: 0.4597 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 50/50 [00:01<00:00, 32.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Val Loss: 0.5533 Acc: 0.7600\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# Author: Xin Xia\n","# Date: 3/26/2023\n","##################################\n","#  Unpretrained Embedding Layer  #\n","##################################\n","use_pretrained = False  # the flag that controls if the model uses an pretrained embedding layer from BERT or not\n","model = select_embedding_layer(use_pretrained) # Create the model instance from TextMLP() object\n","optimizer = torch.optim.AdamW(model.parameters(), lr= learning_rate)  # optimizer used in model training \n","print(\"\\n####### Training a Model with Unpretrained Embedding Layer ######\\n\")\n","\n","# model training \n","trained_model, loss_list_un = train_model(model, loss_function, optimizer, train_dataset, num_epochs, device, batch_size)\n","# evaluation \n","evaluate(trained_model, loss_function, optimizer, test_dataset, 1, device, batch_size)\n","# training loss\n","plot_loss(loss_list_un, use_pretrained)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"GvRtlAk4t26r","executionInfo":{"status":"ok","timestamp":1679841869844,"user_tz":-480,"elapsed":123453,"user":{"displayName":"Xin Xia","userId":"08905681214024585973"}},"outputId":"a05b00dc-54c7-42bb-c9c9-a321b2eef582"},"id":"GvRtlAk4t26r","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","####### Training a Model with Unpretrained Embedding Layer ######\n","\n"]},{"output_type":"stream","name":"stderr","text":["epoch0: 100%|██████████| 200/200 [00:02<00:00, 79.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50 \n","Train Loss: 0.6800 Acc: 0.6438\n"]},{"output_type":"stream","name":"stderr","text":["epoch1: 100%|██████████| 200/200 [00:03<00:00, 58.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/50 \n","Train Loss: 0.6530 Acc: 0.8213\n"]},{"output_type":"stream","name":"stderr","text":["epoch2: 100%|██████████| 200/200 [00:03<00:00, 60.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/50 \n","Train Loss: 0.6310 Acc: 0.8488\n"]},{"output_type":"stream","name":"stderr","text":["epoch3: 100%|██████████| 200/200 [00:02<00:00, 84.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/50 \n","Train Loss: 0.6121 Acc: 0.8513\n"]},{"output_type":"stream","name":"stderr","text":["epoch4: 100%|██████████| 200/200 [00:02<00:00, 85.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/50 \n","Train Loss: 0.5943 Acc: 0.8525\n"]},{"output_type":"stream","name":"stderr","text":["epoch5: 100%|██████████| 200/200 [00:02<00:00, 84.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/50 \n","Train Loss: 0.5788 Acc: 0.8525\n"]},{"output_type":"stream","name":"stderr","text":["epoch6: 100%|██████████| 200/200 [00:02<00:00, 84.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/50 \n","Train Loss: 0.5694 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch7: 100%|██████████| 200/200 [00:02<00:00, 81.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/50 \n","Train Loss: 0.5571 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch8: 100%|██████████| 200/200 [00:02<00:00, 81.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/50 \n","Train Loss: 0.5480 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch9: 100%|██████████| 200/200 [00:02<00:00, 84.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/50 \n","Train Loss: 0.5396 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch10: 100%|██████████| 200/200 [00:02<00:00, 84.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11/50 \n","Train Loss: 0.5332 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch11: 100%|██████████| 200/200 [00:02<00:00, 85.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12/50 \n","Train Loss: 0.5259 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch12: 100%|██████████| 200/200 [00:02<00:00, 85.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13/50 \n","Train Loss: 0.5206 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch13: 100%|██████████| 200/200 [00:02<00:00, 82.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14/50 \n","Train Loss: 0.5159 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch14: 100%|██████████| 200/200 [00:02<00:00, 82.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15/50 \n","Train Loss: 0.5121 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch15: 100%|██████████| 200/200 [00:02<00:00, 84.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16/50 \n","Train Loss: 0.5079 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch16: 100%|██████████| 200/200 [00:02<00:00, 85.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17/50 \n","Train Loss: 0.5038 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch17: 100%|██████████| 200/200 [00:02<00:00, 84.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18/50 \n","Train Loss: 0.5032 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch18: 100%|██████████| 200/200 [00:02<00:00, 84.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19/50 \n","Train Loss: 0.5010 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch19: 100%|██████████| 200/200 [00:02<00:00, 81.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20/50 \n","Train Loss: 0.4966 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch20: 100%|██████████| 200/200 [00:02<00:00, 82.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21/50 \n","Train Loss: 0.4949 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch21: 100%|██████████| 200/200 [00:02<00:00, 84.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22/50 \n","Train Loss: 0.4920 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch22: 100%|██████████| 200/200 [00:02<00:00, 85.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23/50 \n","Train Loss: 0.4899 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch23: 100%|██████████| 200/200 [00:02<00:00, 84.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24/50 \n","Train Loss: 0.4878 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch24: 100%|██████████| 200/200 [00:02<00:00, 84.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25/50 \n","Train Loss: 0.4861 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch25: 100%|██████████| 200/200 [00:02<00:00, 81.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26/50 \n","Train Loss: 0.4855 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch26: 100%|██████████| 200/200 [00:02<00:00, 83.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27/50 \n","Train Loss: 0.4834 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch27: 100%|██████████| 200/200 [00:02<00:00, 85.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28/50 \n","Train Loss: 0.4817 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch28: 100%|██████████| 200/200 [00:02<00:00, 84.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29/50 \n","Train Loss: 0.4796 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch29: 100%|██████████| 200/200 [00:02<00:00, 85.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30/50 \n","Train Loss: 0.4794 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch30: 100%|██████████| 200/200 [00:02<00:00, 85.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31/50 \n","Train Loss: 0.4779 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch31: 100%|██████████| 200/200 [00:02<00:00, 82.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32/50 \n","Train Loss: 0.4768 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch32: 100%|██████████| 200/200 [00:02<00:00, 82.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33/50 \n","Train Loss: 0.4757 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch33: 100%|██████████| 200/200 [00:02<00:00, 85.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34/50 \n","Train Loss: 0.4756 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch34: 100%|██████████| 200/200 [00:02<00:00, 84.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35/50 \n","Train Loss: 0.4751 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch35: 100%|██████████| 200/200 [00:02<00:00, 85.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36/50 \n","Train Loss: 0.4737 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch36: 100%|██████████| 200/200 [00:02<00:00, 85.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37/50 \n","Train Loss: 0.4736 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch37: 100%|██████████| 200/200 [00:02<00:00, 80.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38/50 \n","Train Loss: 0.4717 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch38: 100%|██████████| 200/200 [00:02<00:00, 82.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39/50 \n","Train Loss: 0.4713 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch39: 100%|██████████| 200/200 [00:02<00:00, 85.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40/50 \n","Train Loss: 0.4704 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch40: 100%|██████████| 200/200 [00:02<00:00, 84.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41/50 \n","Train Loss: 0.4708 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch41: 100%|██████████| 200/200 [00:02<00:00, 85.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42/50 \n","Train Loss: 0.4700 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch42: 100%|██████████| 200/200 [00:02<00:00, 85.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43/50 \n","Train Loss: 0.4689 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch43: 100%|██████████| 200/200 [00:02<00:00, 80.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44/50 \n","Train Loss: 0.4685 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch44: 100%|██████████| 200/200 [00:02<00:00, 81.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45/50 \n","Train Loss: 0.4677 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch45: 100%|██████████| 200/200 [00:02<00:00, 84.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46/50 \n","Train Loss: 0.4673 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch46: 100%|██████████| 200/200 [00:02<00:00, 84.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47/50 \n","Train Loss: 0.4670 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch47: 100%|██████████| 200/200 [00:02<00:00, 84.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48/50 \n","Train Loss: 0.4674 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch48: 100%|██████████| 200/200 [00:02<00:00, 84.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49/50 \n","Train Loss: 0.4666 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["epoch49: 100%|██████████| 200/200 [00:02<00:00, 82.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50/50 \n","Train Loss: 0.4658 Acc: 0.8538\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 50/50 [00:00<00:00, 1115.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Val Loss: 0.5540 Acc: 0.7600\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABQmElEQVR4nO2deZgcVbn/P+9ksu8hhJAEsgCBsEPCRQQEFSSggHrhCi6AitsFxeWqcN0QvS64XOW6oD8XFBRcUUQFEVlkEUgIIdskDJPJpDPpzHQmPUs6PTOdnN8fp2q6el+mqrdzPs/TT9de51unqt467znnPaKUwmKxWCzm0lTtBFgsFoululhDYLFYLIZjDYHFYrEYjjUEFovFYjjWEFgsFovhWENgsVgshmMNgaVoROSvInJ1nvV3iMgXK5mmWkNENojIuQEc91wRCfl93BznelRErvXpWDeLyF151reLyHnO9H+LyI/8OK+lNKwhKBERGfD8DojIPs/828o4XsYD7jw8SkRuSFt+g7P85lz7era9Q0SGnHT1iMhDInJMqenzopS6UCn1M+f414jIE+UeK1fa/XwJlZieRc61bR7NcZRSxymlHvUpWUXjpH1v2v35iUqnYzQopb6klAok753rc2QQx24ErCEoEaXUFPcHdAAXe5b9wsdTbQGuSlt2tbO8WG510rkA6ALu8Cdp9cdoX/B+HSNgTvLen0qpW6udIIum1u8dawh8QkSaRORGEXlZRHaLyK9FZJaz7vsi8jvPtl8VkYdFZDLwV2Ce5ytunrPZc8AkETnO2ec4YIKzvCSUUjHgl8DxWdK9WESiItLkzP8/EenyrL9TRD7sTD8qIteKyDLgduAMJ81RzyFnisifRaRfRJ4RkSNKTa/n3Dc71/HnzvE2iMgKz/p2EblJRDaKyB4R+amITHDWnSsiIRH5pIiEgZ/myyPgcec/6mg6wyn1PCki/ysiu4GbReQIEfmHs39ERH4hIjPS0nRekemfJyK/E5FuEdkqIh/yrJvolOr2iMhG4LRRXsffiMhdTjrWichS59p1ich2EXld2m5HiMizItInIn/0XCdE5BUi8pRz36wVjyvMuZ8ec87zEDA7LS3vEJFtzvX7VJZ03uVMuyW0q0Wkw7nWn/JsO1FEfuZcn00i8gkpw3WWLz9F5OPieW6dZbeJyLed6eki8mMR2SkiO0TkiyIyxlmXce+UmrZKYg2Bf3wQeCNwDjAP2AN811n3MeAE5+Y4G3g3cLVSai9wIdDp+Yrr9BzzTpKlgqud+ZIRkSnA24A16euUUluBPuAUZ9GrgAHRL3scPY+l7bMJeD/wtJPmGZ7VVwCfB2YCrcD/lJNmD5cA9wAzgPuA76StfxtwAXAEsBT4tGfdXGAWsBB4L/nz6FXO/wxH09PO/OlAG3CIo0WALzv7LwMOI/9DnjX9og3vn4C1wHzgtcCHReQCZ7/POZqOcPTlrJspkovR989M9H3wIPr5nw/cAvwgbfurgHcBhwIJ4DYn3fOBPwNfRF/b/wJ+JyIHO/v9EliNNgBf8KZbRI4Fvg+8A339DkKXVvNxFnA0+vp81nNffg5YBCwBzgfeXsxFyEK+/LwLWOkxDM3o+/vnzvo70NfmSPTz8zrA69pKv3dqF6WU/ZX5A9qB85zpTcBrPesOBYaBZmf+dKAH2AZc6dnuXCCUdtyb0Tfh4Wj301jn/zBn+c259vUc4w4gDkSBMPoldESObe8EPop+cW4GbkW/6Bc7+zc52z0KXOtMXwM8keWcP/LMXwS05Dhn1rSnneNm4O+edccC+9Ku//vTzvey5/hDwATP+px5hH6pKDe/PBo7CtwDbwTW5LgncqbfuR860o51E/BTZ7oNWOlZ995cee2sV2iDHvX8LvCk4yHPthcDA8AYZ36qs/8MTx58JS3dQ8AY4JPAnWnnfhD9wj8c/WKc7Fn3S+AuZ/qzwD2edZOd43qvl7utmx8LPNs/C1zhuT4XeNZdW8T1ObKIZzo9P/8KvMeZfgOw0Zk+BBgEJnq2vRJ4pNh7p5Z+Ne23qjMWAveKyAHPsv3oG2aHUuoZEWkD5gC/LuaASqkOEWkFvgS8pJTaLiKlpOnrSqlPF96Mx9BfriG0i+RR9FdbHPinUupA7l0zCHumY8CUHNsl0AYunbHol3Ou400QkWalVMJZtt2zfhv6y86lWykV98zny6NceI+PiBwCfBs4G/0CbUKXLHKRNf1OWuZJqlttDPBPZ3oemdoKcapSqjXHul2e6X1ARCm13zMPOq/c9KSfeyz6K38hcLmIXOxZPxZ4xEnzHqVLut59D3OmUzQppfY6bpN85Lqf0q9PSj4VSxH5+TPgA8D/Q5c63FL5QrTunZ5nssmPNFUD6xryj+3AhUqpGZ7fBKXUDgARuQ4YD3QC3tYchcK//hztWvp5ge1Gw2PoB+FcZ/oJ4EyyuIU8jDZsbQcw23FbASD6iVpIcS89l8M804ejr69Lehrz5VEuPenLv+QsO0EpNQ39cijJOnvSsjUtLVOVUhc563dm0VZJ0s89DETQ6b4zLd2TlVJfQad5pui6L+++LimaRGQS2j1UDjtJdSsdlmvDAhTKzz8AJ4rI8egSgdsgZDu6RDDbcx2mKaWO8+xbN6GdrSHwj9uB/xGRhQAicrCIXOpML0X7VN+O/tL+hIic7Oy3CzhIRKbnOO6v0L7HnKUIEZmQ9ivpxaSUegn9Vfh24DGlVJ+Trn8ntyHYBSwQkXGlnMtzzg7gGeCrIjJFRMYDH0e/cP5VwqGuE5EFTmXmp9DXKxc58wjoBg6gfc75mIp2q/Q6/vKPl5BWL88C/aIrsyeKyBgROV5E3ErhXwM3ichMEVmArt+oJG8XkWOdl/UtwG+dEsRdwMUicoGT5gmiK+YXKKW2AauAz4vIOBE5C+2Gcvkt8AYROcu5b26h/HeQ9/rMB64vYp9xac/JGArkp1Oi/C3axfWsc9+ilNoJ/A34hohME90Q4QgROadMPVXFGgL/+DbaD/83EelHv8xOd9wAdwFfVUqtdV66/w3cKSLjlVItwN1Am+hWGF7XBkqpfUqpvyul9pGd+eiXuPdXTkudx4DdSqntnnkBns+x/T+ADUBYRCJlnA/gLWhXWSuwA10h+Po0d04hfol+INuAl9EGNxdZ8whGWlb9D/Ckkw+vyHGMzwOnAr3oStPfl5DWEZyX6huAk4Gt6K/tHwHuB8Hn0SWjrY6+YhoKrJXUfgTfKidtDnei63zC6NZqH3LSvR24FH0Pd6O/jD9O8l3yVpL1YZ/DU5JVSm0ArkPn2U60C6bcTnK3OPtuBf6OflkPFthnA6nPyTspLj9/BpxAZh5cBYwDNqK1/BZd71R3iFOxYbHUHSLSjq5Y/nu102KpLiLyAXRFsu9f5CJyONACzHVKyw2HLRFYLJa6Q0QOFZEzHZfM0eh6tHsDOE8TukXdPY1qBADbashisdQl49B9H9wmzvcA3/PzBE6l9y60i26ln8euNaxryGKxWAzHuoYsFovFcOrONTR79my1aNGiaifDYrFY6orVq1dHlFIHZ1tXd4Zg0aJFrFq1qqx9Q6EQCxYUCm3SWFjNZmA1m8FoNItIzo6aRrmGpk2bVu0kVByr2QysZjMISrNRhiAeL6WfUmNgNZuB1WwGQWk2yhA0NRklF7CaTcFqNoOgNBt1JZub665KZNRYzWZgNZtBUJqNMgSxWKzaSag4VrMZWM1mEJRmowzBjBkzqp2EimM1m4HVbAZBaTbKEHR1dRXeqMGwms3AajaDoDQbZQhMa3MMVrMpWM1ZiMVg797829QZQeWzUYagra2t2kmoOFazGVjNWdi0CVpaKpOYChFUPtdd0LkVK1aocnsWWywWg1i9Wv8vX17ddNQIIrJaKbUi2zqjSgSbNm2qdhIqjtVsBlazGQSl2ZYILBZLY2JLBCnYEoGD/YIwA6vZDKxm/7AlAovF0pjYEkEKtkTg0NraWu0kVByr2QysZjMISrNRhuDwww+vdhIqjtVsBlazGQSl2ShDEA6Hq52EimM1m4HVbAZBaTbKEMyaNavaSag4VrMZWM1mEJRmowzBwMBAtZNQcaxmM7CazSAozUYZgnHjxlU7CRXHajYDq9kMgtJslCGwWCwBceBAtVNgGQVGGYKhoaFqJ6HiWM1mUFXNnZ2wZg3s31/R09p89g+jDMGUKVOqnYSKYzWbQVU19/To/0Sioqe1+ewfgRkCEfmJiHSJyPoc698mIi+KyDoReUpETgoqLS497g1rEFazGVjNZhCU5iBLBHcAK/Os3wqco5Q6AfgC8MMA0wLA3Llzgz5FzWE1m4HVbAZBaQ7MECilHgdymi+l1FNKqT3O7L+AwIdY6ujoCPoUNUdNa+7sTMaD8ZGa1hwQVrMZBKW5VuoI3g38NddKEXmviKwSkVXhcJhoNEokEqGrq4u+vj5CoRDxeJy2tjaUUrQ4oxK5kfpaWlpQStHU1EQ8HicUCtHX10dXVxeRSIRoNEpnZyexWIz29nYSiQRbtmxJOYb739raytDQEB0dHQwMDBAOh+np6aGnp4dwOMzAwAAdHR0MDQ2NxAVJP8aWLVtIJBK0t7cTi8Xo7OwsW1NbW1teTfPmzatZTVuffrosTYXy6cgjj6y7fBrtvTdlypSqaXKvZ6Wfp+Hh4bya9kSj9PT01FQ+jfbemzFjRtn5lI9Ao4+KyCLgfqXU8Xm2eTXwPeAspdTuQsccTfTRTZs2sWzZsrL2rVdqWnNA0SFrWnNAVFXz+vUwOAjHHw/jx1fstAU1N2D00dHkc81GHxWRE4EfAZcWYwRGi2kvB7CafUMp7cqqcBPJYrH5bAZBaa6aIRCRw4HfA+9QSm2pxDntQBZmEIjmaBR27oRQyP9j+4DNZzMISnNzIEcFRORu4FxgtoiEgM8BYwGUUrcDnwUOAr4nIgCJXMUWv7BfEGYQWIkAarYHrc1nM6i7EoFS6kql1KFKqbFKqQVKqR8rpW53jABKqWuVUjOVUic7v0CNADBSuWMSVrMZWM1mEJTmWmk1VBGWLFlS7SRUHKvZDKxmMwhKs1GGIFSj/t0gsZrNwGo2g6A0G2UI5syZU+0kVByr2QysZjMISrNRhiAajVY7CRXHajYDq9kMgtJslCGYNGlStZNQcaxmM7CazSAozUYZgkSFw+TWAlazGVjNZhCUZqMMwYEabQMeJFazGVjNZhCUZqMMwYQJE6qdhIpjNZuB1WwGQWk2yhD09fVVOwkVx2o2A6vZDILSbJQhmD17drWTUHGsZjOwms0gKM1GGYLOzs5qJ6HiWM1mYDWbQVCajTIEixcvrnYSKo7VbAZWsxkEpdkoQ7B58+ZqJ6HiWM1mYDWbQVCajTIExxxzTLWTUHGsZjOwms0gKM1GGQI7kIUZWM1mYDX7h1GGwA5kYQZWsxlYzf5hlCFoaWmpdhIqjtVsBlazGQSl2ShDcPTRR1c7CRXHajYDq9kMgtJslCHYunVrtZNQcaxmM7CazSAozUYZgnnz5lU7CRXHajYDq9kMgtJslCGIRCLVTkLFsZrNwGo2g6A0G2UIpk2bVu0kVJy60KyUr4erC80+YzWbQVCajTIE8Xi82kmoOFazGTSc5gMHYPNm2Lcv5yYNp7kIgtJslCFoajJKLmA1m0LDae7vh4EBCIVyblIRzf390NXl7zEHB+HFF2FoqORdg9LcYHdPfpqbm6udhIpjNdcgSkF7e1kvglzUvOZS2L8fWlv19JgxOTcrWfOGDfoFXApbtsD27aXtU4jubhgehnXrIBzOv21vL3jqBYLKZ6MMQSwWq3YSKo7VXIP09cHu3dDR4dsha15zKaRr2b0bsrhEcmoeGoLVqzOXx+P6BVxL7NiRf31rK2zbNjIbVD4bZQhmzJhR7SRUHKu5Bglg3Nma1zwa2tv113waOTUPDASXlr17taEK8hx5CCqfjTIEXX77+uoAq7kGcUsCPr5MAtGsFOzcqV016QwPQ5UHhqlKPre0wKZNuiLbT/bu1b8CBKXZKEOwYMGCaieh4ljNNUgiof99LBkEorm3V7/ss1XYtrdrI1HEyysoFixYoI1qrRv+dLI1l25p0b8CBHVvG2UI2traqp2EimM11yn795fUv8IXzUNDqf5511BlM1juMp/7gABZ6wOy0dbWpite/a7MzcWuXf4cZxSGK6h72yhDsHTp0monoeJYzWUSj+dtwx4oSsELL5RUmeyL5nXrtNuj2hSpu6L3djyetylrVor8yi+FoDQHZghE5Cci0iUi63OsFxG5TURaReRFETk1qLS42IEszMAXzRs2wMaNoz9OObhf2T09Re9iTD4fODDS8qdozQMD2pU1Gsop+RTp9y+FehyY5g5gZZ71FwJHOb/3At8PMC2AHcjCFIzQvGcPRKMjs8uWLdOunVJ6ng4Pl7Z9LdDSMtIXoOh83rxZN0HNRn+/LgkF0JIrCOpuYBql1ONAvk+aS4GfK82/gBkicmhQ6QGDvpo8WM0O8XjlfMnFolRqO/KuLl1BWwxtbfDyyyOzmzZt0i+0LM0sc/Lii6VtXwt43HW+3NuhUOkGtIrUY4mgEPMB75MZcpYFhhFfimkYp7m/n2WJROYX3ssv6xdtrT3w4XCyeeb27cketSWSNZ8PHNAdq7y9V3ft0svq5AsYkZyrArm3d+7UpYQape5KBH4iIu8VkVUisiocDhONRolEInR1ddHX10coFCIej9PW1oZSamQ4N9d6trS0oJTimWeeIR6PEwqF6Ovro6uri0gkQjQapbOzk1gsRnt7O4lEgi1btqQcw/1vbW1laGiIjo4OBgYGCIfD9PT00NPTQzgcZmBggI6ODoaGhmh1Hur0Y2zZsoVEIkF7ezuxWIzOzs6yNbW1teXVtHHjxprVtNXx25aqKV8+vfz442x/+WVeXr8+RVOku5ve3t6SNG3bti1FU3d3N319faPOp4GBAXp6etgTjdLf3z+iqbOzM0WT20IkWz7FYjEikchIPq1Zs4ZYLMbOcDipKZHQA5l0d48co/3ZZ7Wml15iXzxOd3f3SD719PQwMDDAjpdeIh4O097ejlKKl52SR7omV7t7Pf16nnp7e+nt7SUSibB37152hsMMDw+P5JM7OMuTTz6ZNZ927txJf38/e6LREU27du1icHCQUCiUkk+uts2bN2tNzz7L4Lp1I/eem0/RaJTu7m72xeMZ+ZRL085wmFgslvE8ufk0PDzMdqeU6mpKf546OztHzhmNRlm7dm3Z914+RAXR/Ms9uMgi4H6l1PFZ1v0AeFQpdbczvxk4Vym1M98xV6xYoVatWlVWeoaGhhg3blxZ+9YrNa3ZDQNw6ql5v/xKoqWF4WiUsSecAJMnJ5evX6+DfR13HEyYUHzali/X/z09sHUrzJoFixePLo3p4Q9OPlnH1HGXn3IKrFkDTU16uoj0DQ0NMW7dutQ0Dw1pd9G4cXDCCXrZunV6+fHH62vi3T49XYsX59a8ebOuhD36aF0ROziojzl+fNGXISfedMyalaw0X748RXdWzZDMq1x4t920STeZXbYMJk3KzHd3/thjMxsPeI+TT0f6dunXOU1XvmOM5nkWkdVKqRXZ1lWzRHAfcJXTeugVQG8hIzBawoUCPDUgJmqO7N6d7LRlCCbmc6CalSrbTRckQWkOLGShiNwNnAvMFpEQ8DlgLIBS6nbgL8BFQCsQA94ZVFpcZs2aFfQpag4TNU+fNk0/xHPnwvxAq51qhlmzZunOVQYRqOahodSK+2xhNqpAUM9zYIZAKXVlgfUKuC6o82djYGCAKVOmVPKUVafimvfsgalTdYXb5MnaLVFhYrEYkyZN0s0rCxmCffuguRnGjq1I2oJiYGCAgrmslK+hr6tNUZr9whMBtJoE9Tw3UBDzwtSsrzxAKqp5eFg3a5wyRfuPm5vhpJP8PYfr9z7mmNQ6AA9jS3mpb9yYP51KaV/6xImlpXNwUP/74TMvgvHFjGVbbNPUOqGi93aNuBqD0lwXrYYsdYLb8MD96nQfnuFhXemVqx1/KQ0W3KZ9uVwC5TR+yPeQHziQ6SZIP1+23qPr1ycrYytAUzHxawJsGGKpb4wyBEMNVCwulprQ7I4KVaEokcPZBh9xr4PfbcQ7O3Vv10oODJPFX51Vs1/09OTud1BF4xLovV2jRjMozUYZAtPqB8BMzZMmTcpc6D7YbqiBvXv9iSbpGoBiX8TFdOQqdKw9ezIWZdXsJzUY6tnEezsozUYZgp4Sgng1CiZq7u3rK7xRS0vp0SRHy+BgcSWSMlxKRWkeDTX4hWzivR2UZqMMwdy5c6udhIoTqOZwWHfJrzFmH3RQtZOQZM2a5PT69YG1Ta8pzRXCPs/+YZQh6PBxsPB6IVDNO3ZUfbjCFOJxcLr0j8xXu7XHaGL6lLBvxTuU+dUTfBTY59k/ChoCEblVRKaJyFgReVhEukXk7YGkJmCOPPLIaieh4lRFc7XcCE4kzcMOOyy5zO+xZWuUFM1BkP7irwFXkX2e/aOYEsHrlFJ9wBuAduBI4OOBpCZgbEjmOmVoKGsFaS62euPM1Fq00YDYmi+2ToPSEPd2iVQzDLXb6ez1wG+UUnXbK6UuQjIPDPg6RGKG5v37/QlBXEmXy+bNuqNakSwebVC4OqTimmvANVQXz7PPVDMM9f0i0gIsBx4WkYOBuvzMqosviM2bfR0iMUPzCy9kP35HR2k9T9euzb3O7zbtJbadzvt1XAMujSCwJQIzqFqJQCl1I/BKYIVSahjYix5drO6wXxAObvgDL93dNRltsRxsicAM7PPsH8VUFl8ODCul9ovIp4G7gHmBpCZg3IEkTKIimmusPfe2GgkQVklM1GyfZ/8oxjX0GaVUv4icBZwH/JgKDDQfBEuWLKl2EipORTTX2NB+8xs99HQW/3zDa86CfZ79oxhD4AY2eT3wQ6XUn4G6DOMZqnRP0hqgpjUHVOHYVYPhEILGRM01fW8HRFCaizEEO5xhJd8C/EVExhe5X80xZ86caieh4vimua9PRxDN1hxTKR3Dp9RK4oAqbmcaOBiPiZob/nnO8nwEpbmYF/p/AA8CFyilosAs6rQfQTQarXYSKo5vmt12/AMDmesOHNDj1r70kj/nGiUDNeaqqgQmarbPs38U02ooBrwMXCAi1wNzlFJ/CyQ1ARN4hMYapCKa3S+XGhnOb0Ixg9M3GDWhucJNc+3z7B/FtBq6AfgFMMf53SUiHwwkNQGTqHbcmSpQ05oDqiNIVMMgVbmDVVU0V5mavrcDIijNxQxV+W7gdKXUXgAR+SrwNPB/gaQoQA740aO2VnD98rNn592sKM3FDKoS5NdeIuHr2MaqkfK5SEzU3FDPc5EEpbmYOgIh2XIIZ7r6/cvLoCaKz8Xywgv54+uEw3pA7XXr8jbfLEpztXtorlvn6+GqMjZ1lXssmzged109zz4RlOZiDMFPgWdE5GYRuRn4F7ovQd3RF/TgHX6yf3/uMX4hGetnaAjydDKpK80+sTfbGMINTk1orqR7LBxm3xNPVO58NUJQz3MxlcXfBN4J9Di/dyqlvhVIagJmdgE3SiNiouYZM2ZUOwkVxzjNO3b4qznfR1cNEdTznNMQiMgs94cOP32X89vmLKs7OmtpEJUKYaLm7u7uaieh4lRNcxVdYr5qztYsugYJ6nnOV1m8GlAk6wPcHBdnuu76d5sYmKsimmssoqeJ4RaM0JzWmdEIzWkE9TznLBEopRYrpZY4/+60O193RgBgsyGjVXkxUXN7vQVgK8bve+BA3nEkalbzgQOj+1Dw1jukRc2tWc0BEtTzXJehIsrlmGOOqXYSgmNgIGsU0BHNSmUPP92ALF60KPfKGiu9AMUNurNmjf7lIK/moaHqjd28Zk1xw4Xu2aNbweUjLe/yam5QgnqHGWUI6nYgi8HBwqOKbd4MWQYnGdG8cyesX+9PetI7L9XAaFVeGn6QlizXu6Dman4EZGvRlH4PtbVBJFLSYRs+n7NQzaEqG4a6Hchi/fqShmr0MqLZz1g0tVQBvWdPhmulKnVBfg0BWiY1V/+lVO7S1+Cg7ifT1aXvy9WryzpFiuZIpLiOkcWyYYN/x/KRag5MMyvLb2wgqQmYlpaWaiehdNyHqZRhJD34rlkk8wGvlLtl/frMYSvb2jKC3W1tby/v+Dt2FOfGyMbWrXrfcLgqTRHL1uwn3vvgxRdzD2fqlk56e/XIeGWSonnbNt0xcvVq/4dKzUUspjUW63bzoQ9AUO+wYkoEzwPdwBbgJWe6XUSeF5HlgaQqII4++uhqJ6HilK15aEi/0GrJpz44qMNqFGDRwoXlHT8cLq0ZYXoJIBbTxqScsQHy9SIvgrI15yOf68V1T3lfgt57JZFIdf+sXl3edfGSdi/m1FzsCzeRyB5WvVjCYX2MYkrILS36g6WI+3eELAYtqHdYMYbgIeAipdRspdRBwIXA/cB/At8LJFUBYZxPsbeX0EMPlfcy37pVP7h+FrcrxI4dO0Z3AK/m9PAX7rVUSleE+tXTs0zXn0uG5sHB4l14xYQ23rFDG77du2HjxuTyrVuTX/iFBk1JLykpVdr1S3t+c+ZzscfcuDHVmJc75Gp3d9IghkKp18fFrSfJVnLLViqKRFLvvf37Yf/+wN5hxRiCVyilHnRnnBDUZyil/gWMz7ejiKwUkc0i0ioiN2ZZf7iIPCIia0TkRRG5qGQFJTBvXl0OtVw+7e3MmTKlvBYj1SgJbN/uy5gGBx98cP4NskXq9C7zuofSt3W/3Gss4FmK5pde0m4079dnenq9X5svv1xcRW1bm36R7duX/WW7b1/hY3i/wPv7SwtdnnZPFsznXPT362Olf3GP5iW7dq2+3rt26esQDifXFaoD8Vamu9cnvQXVCy/ACy8E9g4rxhDsFJFPishC5/cJYJeIjAFyPg3O+u+iSxDHAleKyLFpm30a+LVS6hTgCgIuYURKbJXQCPgykEUsFrxhiMV0CaTcL2xPvKWCmrP5WV94obTzlerbLjewXpFfqSmas13D9PSm14UUU/Irs54qhQ0bdAu2YsnjSin73t6yBZ5/vrx98+H92i+lVOo1SBs25M2L6DPPlJ6uIigmDPVbgc8Bf3Dmn3SWjUGPXpaLfwNalVJtACJyD3Ap4C03KWCaMz0dCLQ5yrRp0wpv1EiIMHny5OzrhoaKC/28b1/h9t1+kN68sbVV+6GPOKK4/T2tonJqdinkFy5k9BKJ0h50yKzkLhbXRecSiWS+kKPRwpqVyp8GP8I1DA/rtBbSmq8epoQWRAU11wvp1ytPE9EpASWhmKBzEaXUB5VSpzi/65VS3UqpIaVUa55d5wNep2DIWeblZuDtIhIC/gJkHfBGRN4rIqtEZFU4HCYajRKJROjq6qKvr49QKEQ8HqetrQ2l1EjNutvmtqWlBaUUW7duJR6PEwqF6Ovro6uri0gkQjQapbOzk1gsRnt7O4lEgi3OF6Z7DPe/tbWVoaEhOjo6GBgYIBwO09PTQ09PD+FwmIGBATo6OhgaGqK1VV+ellWrYPfukWNs2bKFRCJBe3s7sViMzs7OEU09PT0MDAywa9cuBgcHRzS5LSS86VBKEQqFGBwcZNeuXQwMDKRo6urqYmBgYETTNueFvnXrVkgkRo61fft2hoeH2emk373Gvb29dO3YQSwWY2c4zPDwMG2OL9v1Vbr/27ZtI5FI0NnZyb54nO7ubvr7+zM0jeRTd3fGMba2t6OUoq2tjcGuLnZt3kxfXx89PT3siUbp7++nq6uLfU4eJvbtS9Xk/A8NDWVoikQi9Pb20hsOE4lEUjRtd3zXRWvq7s7Ip1AolJJP6ZrS88mrqbu7m33xOJ2dnZn5BGx1+n9s376dod5edra0EIvF9LXt7qb3+ecLa1qzBkKhnJr2RKP+aFq3jv7W1sKanH9vPrmaent76e3tLaipo6Mjbz75pikapT8azdDU7tQF+Kmp0L23Z8+ekt97bW1txAt8/Igq8PUjIkuB/wIW4SlBKKVeU2C/y4CVSqlrnfl3oAe4ud6zzUedNHxDRM5Ah7c+XimV0+W0YsUKtWrVqrxpzkUkEqlONE73K+f447UffMkSaMphg71fRGPHwgknJIuxy51GWv392geZzQWw3NOQ68UX2dPdzcxXvUr7d71fYsuWgTvsnfec7v4tLdk7Ai1apJd7vyCnT8/tNli+PPvx07/8lixJVph69zniCO3Ddhk/XpceDjpI68nSUWpPNMpMb2TK9DSMlhNOKM3V4+f558zJ2vomQ7MBNIzmCROKbr20Jxpl5mtfW9ZpRGS1UmpFtnXFuIZ+A9wO/IjUAWoKsQM4zDO/wFnm5d3ASgCl1NMiMgGYDYyynVl2mpuLkRsgoZB+Ya5Zk/rCBl10L7aHbp7xB9JpHjOmhAQ6JBLZjUAu/PAd58JrBCDVbZOjt2xZmkuh1PoSPyuWcxwrcM01SMNoLqEJa1Cai6ksTiilvq+UelYptdr9FbHfc8BRIrJYRMahK4PvS9umA3gtgIgsAyag+ykEQqySTSEjkeJfAAMD+qvfz96/DjmLhPkq2vwM77trV+r87t2jMxxF+NozNFd70JY8MYJKJkeDh0JF/0bEavaPYgzBn0TkP0Xk0LQxCvKilEoA1wMPApvQrYM2iMgtInKJs9nHgPeIyFrgbuAaVchXNQoCG7xDKV30d1tDRKO6grXYdtyuASjGEBTq8OQ24YtGYXiYKVOn5j9n0HHY09uWt7friuB0Ss32PL1HMzT73RszAIM9WnLmcwNjNftHMb6Sq53/j3uWFTUegVLqL+hKYO+yz3qmNwJnFpEGX+jq6mJREBEL3ZdYOAyHHppsG52vq/vevZDe6qGYEkuxrVUcl8qenh4mZlvv+tezhVTI56IKhXwdaH4EbxvuYvzpeZqZ7unpYWKQfUZqMPxx4JprEGM1B3DcgoZAKVVj0azKZ8GCBeXtGI9rl0YxA2F0dBTXFj5bRxq/fO0el9ScOXNyb5etrqGQMUokqhfSuEjyam5QrGYzCEpzvqEqX+P8vznbL5DUBExbud34X3pJf+0X0xa8u7u6IX83bkzxSecNtxCkMaoiow4xUYdYzWYQlOZ8JYJzgH8AF2dZp4DfB5KiAFm6dGlpO+zaldqrttJx94eHU7/a9+0ruQXKwnzByLIZgngcJgZR+KwceTU3KFazGQSlOd9QlZ9z/t+Z5feuQFITMCUP6hAKpXbxV2rUUSJHOHCguK9vb2Xuxo0lB4FzO48VTQO0xDAuuCBWsykEpblgHYGIjAf+ncwOZbcEkqIAGfWgDpGIbhm0cCF4O6aV09Cpo0N/8S9blhqgymcWL15c8shP9U7NDdJSAaxmM6j44PUe/oiOEZQA9np+dUfeEkE0Wvhr222amas1UCG3jbeOwT3Gpk2BRrLcunWrLlUE3Uy0hrBfimZgNftHMc1HFyilVgZy9gozUiJwQ9AODenWQAsXJnuwpvf49ZLeCSuR0G3Ui22SWoXY/osXL67LMQVGg/1SNAOr2T+KKRE8JSInBHL2CtPa2qr9/hs26Fgxmzdrt4nXtZNtmMFcJYC+Pt1CKJdrJx6v+ghf26swbGK1sZrNwGr2j2IMwVnAameAmRdFZJ2IvBhIagLm8MMP1y2B8jXvLNafHosV7i/gjmlaRebOnVvaDrFY+SGTa4SSNTcAVrMZBKW5GNfQhYGcuQqEw2EOL7RRsf56b31Dvn1KGYEpACK7d3NoqTePn7GGqkBZmuscq9kMIrt3c2gAx81pCERkmlKqD6i9wCplclAuX3l6RWpra2kdq2ow9ozLdNMG48FqNgWr2T/yuYZ+6fyvBlY5/6s983XHvlwxYtJDLRQyAnXUAqeiEVdrBKvZDKxm/8hZIlBKvcH5b4yq+USCsWPH+nOscsfVrQK+aa4jrGYzsJr9o6iRWkRkJnAUerwAAJRSjweSoqAwsM2xxWKxFEPBVkMici3wOHpcgc87/zcHm6wA6OxEvfBCQ4RQKIXhfKGwGxSr2QysZv8opvnoDcBpwDal1KuBU4BoIKkJkkcfZcbHPgZnnQU33FDt1FSMSe64xAZhNZuB1ewfxRiCuFIqDjrukFKqBTg6kNQEyWOPJaeffBK+8Y2qd/aqBL11VJ/hF1azGVjN/lGMIQiJyAzgD8BDIvJHoPaGaCrEu5yAqYccov/vvhs+8pGGNwazDzqo2kmoOFazGVjN/lHQECil3qSUiiqlbgY+A/wYeGMgqQmSs85i+733wp//DM8+CyedBE88AaedVlfNQUslHGBk01rFajYDq9k/JN9Y8SIyBtiglDomkLOXwYoVK9SqVWV0Y0gkUsM9DA3BK1+ZnJ8wAX71q+KGo7RYLJZqkS8wZh5EZLVSakW2dXlLBEqp/cBmESkYmaHmaW5ODeE6bpyuK3ArjuNxuPRSeOqp6qQvIGyoXjOwms0gKM15SwQAIvI4uqXQs3jGIVBKXRJIigpQdokAYPXq7MuVgle/Ouki+r//gzPOKO8cFovFEiSVLhE4fAZ4A3AL8A3Pr+7IaU1F4NFH4eab9fwHP9gwlcj2q8kMrGYzCEpzMYbgIqXUY94fcFEgqQmYgoM6vOENcPHFevquu4JPUAWwg3eYgdVsBtUcmOb8LMvqMjT1y8X0yvv4x/X/t7+tB6+pc7blCrTXwFjNZmA1+0dOQyAiHxCRdcDRzoA07m8rUJcD0yxcsQJOPTX/RpMmwUpnZM53vhNWrKj64DKjYb6BraCsZjOwmv2jUBjqi4H7nH/3t1wp9fZAUhMwoVBI1wcUqmz54hfhfE9B6N3v1gbhxfqzf11dXdVOQsWxms3AavaPnIZAKdWrlGpXSl2plNrm+fUEkpIKMGfOnORMoZgdX/6yDkPh5V3v0gahjrq2z5w1q9pJqDhWsxlYzf5RTB1BwxCNRpMzy5YVdhOdcw4891zm8te8xtd0BclADY+eFhRWsxlYzf5hlCEoK3KfCKxaBQ88AN7xUVes0L9//rOmm5pOmDCh8EYNhtVsBlazfxhlCBKJRPk7z54N998Pt9ySuvwjH9HxilpbR5e4gEjs31/tJFQcq9kMrGb/MMoQHDhwIHWBiP4/9NDiD3LRRfC3v8GYManLr7gic+zjGkClazYAq9kMrGb/CNQQiMhKEdksIq0icmOObf5DRDaKyAYR+WWQ6clarFq+HObNK63b9qxZ8Mwz2mX0l78kl7/1rbBrF9x3n+6pXAMuo3HjxlU7CRXHajYDq9k/ihqzuBycyKXfRXdICwHPich9SqmNnm2OAm4CzlRK7RGROdmP5g99fX1MmzYt9wbHHgsbN+Zen405c7RBWOGE8Hj965PrVqyA228vPaE+snfvXqZMmVLVNFQaq9kMjNUcwHGDLBH8G9CqlGpTSg0B9wCXpm3zHuC7Sqk9AEqpQBsGz549O/8G48eXf/Bnn81ctmoV7NlT/jF9YMaMGVU9fzWwms3AavaPIA3BfGC7Zz7kLPOyFFgqIk+KyL9EZGW2A4nIe0VklYisCofDRKNRIpEIXV1d9PX1EQqFiMfjtLW1oZSipaUFgE2bNgHQ0tKCUooXX3yReDxOKBSir6+Prq4uIpEI0WiUzs5OYrEYnZ2dJBKJka7cbpAn93/79u0MDw+zMxwmFosRiUTo7e2lt7+fyAMPEHv8ccK/+Q3KdUOdf77eN5Gg4/nnQSl2PP00iUSCzs5O9sXjdHd309/fz55olJ6eHgYGBti1axeDg4OEQiGUUmxtb09NT3s7SilCoRCDg4Ps2rWLgYEBenp62BON0t/fT3d3N507d5avqbeXSCRCLBZjZzjM8PAw27dvz3qMbdu2VUzTvng8r6bu7u6G01Qon9rb2xtOU6F8cp/zRtJUKJ86tm8v+b3X1tZGPB4nHwXDUJeLiFwGrFRKXevMvwM4XSl1vWeb+4Fh4D+ABcDjwAlKqWiu444mDLVSCnEriLNx4ACsWVPWsTOIxeBVr9LTH/4wfOtbqeu/9jUd+jpgCmpuQKxmMzBW84qskaQLMtow1OWyAzjMM7/AWeYlBNynlBpWSm0FtgBHBZWgzZs359/Az5tq0iR429v0dLoRgGRwu4BpNzAwl9VsBlazfwRpCJ4DjhKRxSIyDrgCHbfIyx+AcwFEZDbaVdQWVIKOOabAiJsicOSR/p3wwx/Ov36vM86P2zktgNHRFi9a5Psxax2r2QysZv8IzBAopRLA9cCDwCbg10qpDSJyi4i4o5s9COwWkY3AI8DHlVK7g0qT6zvLy/Tp+ucHIroS+eyz4Y47dOXxqlVw0EF6/TnnwCc+kdz+Qx8Cb1CpWEwPoTkK7OAdZmA1m0HVhqqsNUY1VGWxHDigX8AHDkAhd1I5vPQSXHll7vVf+hJ85jPg9iJ87jl/3VYWi6V+qdJQlQ2DW6tekKYm7eOfMgVOOSX5Be8XRx0F3/1u6rKf/jQ5/d//nTQCAE8+Wfap3NYRWQmHyz5uLZNXc4NiNZtBUJqNMgRHH3106Ts1NcHChf4n5vTTdSC7Cy/UL/oTToAf/CD7toXqGtw6hh/9SJdiPCzKlfYVK/TQnI89Vnraa5ycmhsYq9kMgtJslCEo278WlFtm9mz4wheSHdmWL4fvfz+5/tvfTk6feSZ873t61DSvO887NsLtt8NZZ6WcYseO9IZaafziF2UmvnYpqLkBsZrNICjNgYWYqEXmzZs3ugOMGwdDQ/4kJhennaYrlF3e8Q64804YHISf/CS5zQUXwNater2XoSGIRrVbC1jwxjfCVVfpimjvNi6xWCAyqsnBBx9c7SRUHKvZDILSbFSJIBKJlL/zySfDccdBOe6l0fChD0G2YHkPPqijnX7mM5nrzjsPrrsu2WHt5z/Xo6u5dHQkp4utN6kjUgYgMgSr2QyC0myUIcgbcK4QY8bo+oIpU1Jr7ZsDLlSJwBNPlL7f6tWwb19y3h1v+ckndchsLw0W133y5MnVTkLFsZrNICjNRhmCQvE2SuK442DBAjjppMqUEm65Bd7zHt2U9Mtfzlx/113wxz/mP8ZTT8FHP5qcP/dc/X/66Q1lDIaCdt/VIFazGQSl2ShD0NTko9wJE+CQQ/R0JULhXnQRvO99uoRw/vnJ5W4ntWOOgfnz4dprU3bb8/e/J2f++c/kC/+734V3vzu5zq1If/WrdYui7d54gQ4PPADpzdcefRRefjlz20QC/ud/9PrRkEjoXwmIn/lcJ1jNZhCUZqMqi5uDduNUklyd6t7/fv2l//a3w5130jxmjC5FnHYa/OY3ye1OPz31BdvXpzvRuYNjv+lN8KtfQXc3XH99yin44x+10dm9G/7rv/SyRx9NNYgf/agugdx7b+60FsMrXqH/n3kmc1S4HDQXuV0jYTWbQVCajTKpsQZsIZOVY47RL99ly7Q7LL35q9urublZu5RAv/DTmp7ylrdkGgFIVlB76xrCYXjoIVi/Hr7yldRSwvr1+v8nP4Gnn0491uAg/Pu/w49/nF/TH/6g/xOJZL+JHL3ifXUB1glWsxkEpbmBPpELY+JAFlOmTtUTP/iBdi1B8h/AbY5WSoX0iy8mR2RzSa+A9nLNNXD55ckSiVtCCIXgjW/U09//Plx9dWrlu7ck8fOfa4PhbTXx8MO6hVQaU7u7YeLEyrjsaoSRfDYIq9k/jCoRdHUFOgBaTbKnp0dPLF8OY8fqae8L0jWOf/1r5jI/8bqlXFwj4NLamjr//vcnp3fs0E1m3dDekBqgz2X/fiZcdRXccENy2e9/rw3Xrl26Ge2//pW5X1+fHiMiXxf+vXu1i6oGGcnnbESjcP/9FUtLpciruUEJSrNRhmDBggXBHbxG6x/mzPEMA/3005n++nSf41NP6UphL66ff9UqXbcwWu65J/vy3/8+/36f+pSul3D55jczt3nhBf2/dm2yYvxLX9L/r3+9Ls2k96YeGIDXvEbXiVx2We5Og+eco/tn3Hln/nQODmaE+sjJvn3ayLkMD+uK/LPOgl//urhjkJbP6Zx3Htx88+jqaoJiYEDnYxnt4/NqLpX2dn2Nhof9O2YA+KrZg1GGoK0tsKEOKt/RrEhK7pI+bpw2au6Lf9UqOMwzvtB3vqPnp0/XdQ3PPZdpTC65RIfP+MY3sn99f/3r+oXrcvPN+t9rCB58MDl98cW50/u73+mSgVtv4HV7nX56apgOl/RWSG96U+r8pz6V+3ygj9nbm/24P/mJDgfyb/+WTFM27rlHu8zOPhsuvTSZple9SgcgjMfh1lvzp8NDznz21tV4S1guDz6o0+jtZFgMJbbkysnVV8Mvf6mN1c6d2Vur5SCrZqXKe5lfdpkuNa1dW9z2kYh2Z/p1HYokqBATRhmCpUuXBnfwCRNg8eLk/Ny5+nfSScG4WopkYTFBqkq5LiK6hPDww/Cxj+n5X/0KPvIR3c8B9P8DD+gv6OZm7U6ZPTv1ReS6YJqadPA7F6V0Bbb7Mn7963U0Vi8f+EBy+stf1k1rc5Ht6/2555KG6JvfhD17Utc/8kjqfEsLpI9lsW5d6nxvr27h9L3vZZ4vmzvp619PVqKDrmyPxzNfYrt2Ze6bhYx8Hh7W1/L22/Pv6F7nN785OVBSIdav11r9KGF4Y2VdfHGmUc5D1nv7jjvgjDP0S72YD79nn0011sVcg3AYVq7UDRzK6exZDgcOwMBAcc9zGRhlCIoamGY0zJqVnJ4/X/+am6s6lkBRgfZ+/GMdYbVQh7RcLFqkfffvfa9uOXTooanrx4zRhuHaazNjI7kRVw8/XP+fdlrq0J4LFui6jWefTS574olRheYGtCFKJPTXaCHe/vbMdLsuqo4ObRSzDUfqkl4q2bIlc5t7781stQXJHuHZeO65kVJH5wMPJAcx+sMf9MvwtNMyjVq6ofGGL3nd63Kfy8s11+j/f/5T/4fD2uAWM7bJ7t2p26UbYch9nHA4ZV3We9sN737zzTrPHn00fykjPURLMXVAd99dOK1+sm2bLmGeey7bXNenzxhlCJYtW1btJGQScKeYxd5SSi4mTtQulvnzR3cyEZg5M/82N9yQ+sJzjYa3k5wXt4NcUxP8+c96+tZbkxFbc5E+7OeECZkls76+ZN3O2WenurE+8IHsrh13RLkvfEHv/+Y3wyc/CX/6U+60nHJKqgshWzPmn/0s+7433aR/6SQSKSWjeZ/+tO4g+MQT8MUvZm5/+eX6P72y0XvdBwf1/1/+oo2fUvrFvWJF8tqnpwHgs5/Vxq69XZcw3L4o6fztbzpY4mteo+e9JSIv3t7voA2nGzbdU8IreG8PDup+LvlKGd5OlVBcvYy3jstbokln377UMC/lEI/r1nIOQQXeNsoQBF4iyEWuEsHUqdp15PfANx5qcji/t7wlOe02X82WzgceSL12hxyi3RHuPm4lMOgH+MYbYcwY2n/2M13X4b78rrlGvyD//nf9Fb1kiV7+utfpl9npp8P//q82Cm5wvueey552ry/dfaGlc58zNPd11+m8/dWvkh3jIPNlXIiHHtIV348+qn3TkHo8l82bc49dcdRR+j89yGAsBm78GtdF+NnP6u3cKLcAn/ucfil5XSHuWBau++ryy3Wdw6tfnTQqLj/6UdLF5xoKdzCmM85I3faf/0z90va2aLvttpF1Gff2wEAW4QUopm/Rhg2pxs0bjsUt0XR1pfaR6e7WHxdnn51c9qEPaYN2xx25zzU8rI2uqz+tlNjzj38UTm8Z1GZTl4Coeolg5kz9MLlfCe6DN2dOamsYHymqRFBpzjhD1xesWJGsaP7Up7SfffVqPf+ud+l6hXy4D9mUKfrlvmQJXHYZi9z1112nXU5ewyMCH/ygrtNw2bgxOf2+9yXDfWfj0ku1qyGXa+r662HevKT/3OtG2LNH10m4L7b77tNGwXW1uPzyl7pC3vsS8bbWylYBn4/bbkuGQ3HdJB/9qG5S/PDDye22bMn/hXv99clWWaBdNbkqw888U+t0jXZ6XYVSsGyZNiZf/7quKP7gB/U/aCP0pz/pzonpzYRvuAFuuy3z3s73DCmV/YNsYEB/ADz9tC7dbd+un1Gvy+zqq/X/U0+lGpumpqQhuOSS3BXHf/+7rgx3S6nf+Y4ODZ/uDfjHP/Q2f/iD/pDJUkqeNVqXaA6MKhG0prdTD4Ljj9c/L24nkEMOgWOPzdwnwKan20tohVFRrr1Wh/Z2mT5d1xe4LZX+8z8LH2PiRG1QfvjDlMUjmqdM0S2b0h8473kh9WtvzJjMEenc1jv336+/rL/2tdT13lZT6S9179f/+eenft3OmZPaIstl+vTsocddvKWBdBeYi7cfxStfmXTBfetb+kv88cd1KSidXKUcSDUCxXDhhbnXfelLumJ2/Hj9W7RIv/hPOSW5zcUXa4P70kup+z71lP5oWLFCu3Y+8xn9Jf35z+v12VqKnXaa/tJ23X0rVuj9HnkEpk3TRsKtBzrrrGTJyVshvnFj8qPh9NP1NXXzN1/roRtvzDSYX/hC6nx3t3Y7uj3ob7pJl8KOPFLPP/44XH45Xd5w8j5iVIngcLdCMkiy+a5nz9Y327hx2ffJtdwH5s6dG9ixa4K0IHtQhOapU3Xlm1sBnd6s8mc/0z2ZzztP592sWakvhPT8evhh/SLI1pP5Na/RX3rZaG7WL/3rrtOVnG5UWffrfdUq/YWcq/nsIYfotDz3HMORCGMvvFC7ot73Pr3Ptm3JF8mkScn90sfL9vb69hv3S3z2bF0SHBrS7qN779W++/RrVmzLpde+Vv+vXat/4XCyYn3GDO2O85YEQb9YvXiNMiRLI6CN5A9+kHpvXHutvm/c6Y98RB/DLTGUwp/+pEuXJ5+sNWczmm69zJln6vz75CeZGVA/B6NKBOFqDtZe6GV/zDGBnDYSkMuplilK8/e+p+sgnngis8JwyhRdIlm6NLUlWDZuv11vP2NG9pLdrbcm+0l48fra3/lO/dI///xMd4C3A5Fbt+Hy1a/qfxEi+/frYzz4oHZxjB0Ln/50/tAfLp/8pPbhe/n+93Vp5fLLM5uJPvdcZgX2ggXat/+vf8GJJyaX/+53+ms4EtHXyFuRfe+9me6cSy7Jnc7f/S73ujVrktPHHQdHHKHT49aNFIO3JL92bfaXs/vxMHVq0k20bVv242WL0+V18V17re5Nf911+dPlGUclqOfZKEMwq9BDXU0mT04d8MYnpo9mMJ46pWjNs2drF0w5zXu//W3dZDaXj9yLt5/DUUfpF2s+148X1+20cKGuEPeWdjwvrqI052v3n+4uO+00/aL+5CcztxXRL+yVK5MtfF75Su2qa27WdSzul/NXvpLcb/z4wtf6iit0XUE673iHvgaeFjQFmTgxu5soHddwnXOObpXU1KRLeN3duffxuhvda/Sb3+he6w88oK/1NddkNslNT88VV+RuPeUyfXpyMqDn2SjX0MDAAFNqIRDZxImpRfUAicViTKrQuWqFimg+80z9K4amJt1J7uMfLxyeIhs/+Umyn8Uf/6gbG6Tdx75oPuwwXVmarRnxsmW6U51bKhk7Vn/dK6XdUe4gRy7/93+Z4UiylZje/ObMZVdfrT+Kli7VrXri8aQBvOSS/CUDt2+Dy5w52nXnupJAf6lfdZV2AW7ZkuqvX7YsMzzIa1+rW7V5O6i5fWe84UqmT88sQX7pS7rZLGhD0dysjWa2up3LLtPpedObdInmqqv0cs/LPxaLEcSdbZQhGBegL74kslUYu5xwgi4ud3b6cqqxbqA5g6hJzccck7+vQT68rpYxY7LWRRSt+bHHdMXjySdro3Lppcl1hx+uDUF65znQLrAf/jCzEl8k2cTUS7a4+ekuOMjsNe7ilnbSn1lPZ8W9n/0sky+5JLVUNnFi5rE8X9RAskL/ne/Mfu50lNIuPm9YlKYmrdtrCHL1oXniCV357LZyuu227CXJs8/WFcsuEyZoI/jss7qzJsHd20a5huqCceOSlYUWi99Mnqx934ceqitCvb3Av/AFXWrJ5n6ZPFlXjhbqyOfFLSWcfbZ2lbhuoSOO0P/pwQ2LYdYsXRL59a9JnHNO8fu5zYWztZRKJ73l13//ty4BuCWlU0/V/94PuqVLc7u9JkzIdL1liwab3jfkpJP0f7ohCwCjSgR1M8apj72Nh2s8mmIQWM1lMm1aZkub0XDrrbrpZ3pAxh/+ULtaCvUTycXKlQAMu53rVq7URiVXZzqAt75V1wEUE4H4uuu0kXQjoro90j//ed3E01vh7bY+KzY8h8vcudo4Dg3p/iSXXJJZirrtNt3U11PhH9S9LaoSsTJ8ZMWKFWpVmcGuaqaOoBjcdsluNMSlS3Xl1aGHpnaAKoCtIzADozXv36/7OATQ2KIgQ0Pw299qt1EFXM+xWIxJ3o6GJSAiq5VSWVs3GOUa6qmngSyam5OVawcfrJurLVmS3Qeah958PUUbFKvZDEY0jxlTHSMA+uX/1rdWxAhAcPlslGuoLjtXZbvBm5uLjoM+O8A4RrWK1WwGVrN/GFUi6Ch18I1a5aSTtIFYtkz/li/POT5vVTvRVQmr2QysZv8I1BCIyEoR2SwirSJyY57t/l1ElIgU0TunfI50u9s3CpMmJfsjuBXMM2akhFs+LD2WTSmtPuqUDM0GYDWbQVCaAzMEIjIG+C5wIXAscKWIZDSgF5GpwA1A4KOCVy0MdSVwfZSHHKKb582bB2QJ1WtAcbomQ28HjNVsBkFpDrJE8G9Aq1KqTSk1BNwDXJpluy8AXwXiAaYFqIEw1EFy2GG6w0qai2jx4sXJfglz5xrRR6EmQ28HjNVsBkFpDtIQzAe8MZBDzrIRRORU4DClVJbhj/ynoUsETU2p3dudFkdbt27VbaeXL9cdYpqaqtfCokLYL0UzsJr9o2qVxSLSBHwT+FgR275XRFaJyKpwOEw0GiUSidDV1UVfXx+hUIh4PE5bWxtKKVqcWOLui7+lpQWlFOPHjycejxMKhejr66Orq4tIJEI0GqWzs5NYLEZ7ezuJRIItzriy7jHc/9bWVoaGhujo6GBgYIBwOExPTw89PT2Ew2EGBgbo6OhgaGhoZPyD9GNs2bKFRCJBe3s7sViMzs7OsjW1tbVl1zR2LN3d3cw96aTsmubPH7mptm/fzvDwMDvDYWKxGJFIhN7eXnp7e4lEIsRiMXaGwwwPD4/E+nf3df+3bdtGIpGgs7OTffE43d3d9Pf3sycapaenh4GBAXbt2sXg4CChUAilFFudAexHjtXejlKKUCjE4OAgu3btYmBggJ6eHvZEo/T399Pd3c2+eJzOzk4SiQTbnMiP3vQsXry44TQVyqepU6c2nKZC+eTSSJoK5dOMmTPLfkfkI7AOZSJyBnCzUuoCZ/4mAKXUl5356cDLgDvkz1ygB7hEKZWzx9hoOpRt2bKFpe6oYIZQULM7IpiLSOowgW68kzpi27ZtLEwfXKbBsZrNYNu2bSzMFqivCKrVoew54CgRWSwi44ArgPvclUqpXqXUbKXUIqXUIuBfFDACo2VJejx3AyhZ86JFyemJE5NDDaaTL3BelZmfLXpmg2M1m0FQmgMzBEqpBHA98CCwCfi1UmqDiNwiInlGnwiOUChUjdNWlZI0z52bWs8wa1ay8nn+fB1Lf+HCZA/nAIfYHA1d6WPcGoDVbAZBaTYq1pDR8VhysXevHrN39uzki/3AAe0eyhZK2Es0Ci+/nH3dqafC88+XlebRsi8eZ2KxA780CFazGeyLx5lY7DgYadhYQw5RN5qgQRTUPHmyLgl4v+6bmgobAdAd17INsXnCCZkheSs4RsCAdzB6Q7CazSAozbVZtg8I00oDUAHN7hCbiYQuRcRiyc5tS5boUZ2amvRAI/v3awMTCuUfBnCUTDDsKxGsZlMISrNRhiBRZKC2RqJimt0ShXcQjZkzdeXzlCnaGLhhMIqtWzjkENi1q+SkJPbvL3mfesdqNoOgNBvlGjqQPhapAVRd80EHZcY3cufzDWQ+Y4buCOeOBuWS3oopS7A95WputNhSeVDVzucqYDX7h1ElAluUrBFc4zBmjB7Bav587U5qbobhYb3MfeGnG4vDD9c/t//DUUfpCmtPnPaRsanHj9f1HwZEqayZ8bgriNXsH0aVCPoMHLyjZjVPmaKboJ54ojYMU6fq+WnTdJ3DtGnJbd22096v/xNP1L+mpowv/7179+qJCRP0vsuXJ8fJbVBGNBuE1ewfRhmC2eWOkVrHNITmuXP1y977wh87NrMlkggcdxwzPGG4R/Aucw2KG9I3vULd68qaOTN1XY2GPs6qucGxmv3DKEPQ2dlZ7SRUnIbRPH164SatEybAhAl052qRtHChHkjdPY7b4skd4GfaND3ojxu2YMkSHdH15JOTx/CWVMrBddXNn6/Hn/aJnJobGKvZP4zqUKaUQvJVUDYgxmju69Nf9s3NqL17kcHB1F7SXhIJ2L07f0ju4eHUEsf+/fo3bpwesLypCXbs0IZh3Dh9bm8HuhkztDtqaAjWrdPLTjwxsxSzZYvu0JfOlCkw4IThamrSnfzyYEw+ezBW84ryxu+yHcocNm/eXO0kVBxjNE+bNtIsdfP27bmNAOjtCo3LkP7CHjMm2T/CrdheuFC7jiZP1m6pU0/VP2+dxLhxupRx0knZO9UdeaTu1e1y7LG6k5639HPKKamuLdAtqjy0O5EwOfpomDMntXXV4sXJcxxySOr5vMycmWziWweMaDaIoDQbVSKwWGqW/ft1hzy3j4UbvmPZsmQdRn+/flGPH6+3czvxNTXp7adPT+2j4basyjX+xN69sG8fuC+X5ct1Ol54IbnNwoX6vLNm6cr8lhZdWpo1C3p6tAE85RRYu1a7usaO1elzQiKPsGSJTt+aNaO8UJZyxxPJVyIwqvnopk2bGnuUsixYzXVCev3HjBmZD/zUqanznpf+pq4ulqUPQ3rkkfqlnYvJk/XPdXm56ViwINmKSyS1BHHiiclpN1KtSGo9CugmvvG4HjLVq83VFItpY9HUpEtA48Zpo9bRoafHjtXzU6dqDePHw4YNyeMcdBBbV63KHLHrhBN0z/WFC5MG7eCDR9eTvYaaILeIkCWoy6ixJQKLxVJfDA2lutlEdOlozJjMfiduXU88rg3MgQOFe7ZHItpNNmZMcn/3+JAshbm49TciupTl1u+4LkN3n74+7cJ0l+3Zo0t7bis1paC3V+/f1aUbFkyerI85PKyN4ihCxtg6AoeW9OKqAVjNZmCU5nHjQISWzZuTL9Xm5uw91V2DMWGCfnkXE95k9uzkS9/d3z2+SGY9ihs+RSTZNHnKlNT0iGjXmHfZzJmpTZVFdEmwuVmXpGbN0utnzdJ1O5MmBZbPRpUIjG1lYDU3PFazGYxGsy0RONjBrs3AajYDq9k/jDIE8+bNq3YSKo7VbAZWsxkEpdkoQxCJRKqdhIpjNZuB1WwGQWk2yhBMG214gDrEajYDq9kMgtJslCGIx+PVTkLFsZrNwGo2g6A0G2UImuqo+7xfWM1mYDWbQVCajbqSzcUOkdhAWM1mYDWbQVCa664fgYh0A+VGXpoNmFbDZDWbgdVsBqPRvFApdXC2FXVnCEaDiKzK1aGiUbGazcBqNoOgNBvlGrJYLBZLJtYQWCwWi+GYZgh+WO0EVAGr2QysZjMIRLNRdQQWi8ViycS0EoHFYrFY0rCGwGKxWAzHGEMgIitFZLOItIrIjdVOT7mIyGEi8oiIbBSRDSJyg7N8log8JCIvOf8zneUiIrc5ul8UkVM9x7ra2f4lEbm6WpqKRUTGiMgaEbnfmV8sIs842n4lIuOc5eOd+VZn/SLPMW5ylm8WkQuqJKUoRGSGiPxWRFpEZJOInNHo+SwiH3Hu6/UicreITGi0fBaRn4hIl4is9yzzLV9FZLmIrHP2uU2KGcBAKdXwP2AM8DKwBBgHrAWOrXa6ytRyKHCqMz0V2AIcC9wK3OgsvxH4qjN9EfBXQIBXAM84y2cBbc7/TGd6ZrX1FdD+UeCXwP3O/K+BK5zp24EPONP/CdzuTF8B/MqZPtbJ+/HAYueeGFNtXXn0/gy41pkeB8xo5HwG5gNbgYme/L2m0fIZeBVwKrDes8y3fAWedbYVZ98LC6ap2helQhf+DOBBz/xNwE3VTpdP2v4InA9sBg51lh0KbHamfwBc6dl+s7P+SuAHnuUp29XaD1gAPAy8BrjfuckjQHN6HgMPAmc4083OdpKe797tau0HTHdeipK2vGHz2TEE252XW7OTzxc0Yj4Di9IMgS/56qxr8SxP2S7XzxTXkHuDuYScZXWNUxQ+BXgGOEQptdNZFQYOcaZzaa+3a/It4BOAM1I4BwFRpVTCmfemf0Sbs77X2b6eNC8GuoGfOu6wH4nIZBo4n5VSO4CvAx3ATnS+raax89nFr3yd70ynL8+LKYag4RCRKcDvgA8rpfq865T+FGiYdsEi8gagSym1utppqSDNaPfB95VSpwB70S6DERown2cCl6KN4DxgMrCyqomqAtXIV1MMwQ7gMM/8AmdZXSIiY9FG4BdKqd87i3eJyKHO+kOBLmd5Lu31dE3OBC4RkXbgHrR76NvADBFxwzF60z+izVk/HdhNfWkOASGl1DPO/G/RhqGR8/k8YKtSqlspNQz8Hp33jZzPLn7l6w5nOn15XkwxBM8BRzmtD8ahK5buq3KaysJpAfBjYJNS6pueVfcBbsuBq9F1B+7yq5zWB68Aep0i6IPA60RkpvMl9jpnWc2hlLpJKbVAKbUInXf/UEq9DXgEuMzZLF2zey0uc7ZXzvIrnNYmi4Gj0BVrNYdSKgxsF5GjnUWvBTbSwPmMdgm9QkQmOfe5q7lh89mDL/nqrOsTkVc41/Aqz7FyU+1KkwpWzlyEbmHzMvCpaqdnFDrOQhcbXwRecH4XoX2jDwMvAX8HZjnbC/BdR/c6YIXnWO8CWp3fO6utrUj955JsNbQE/YC3Ar8BxjvLJzjzrc76JZ79P+Vci80U0ZqiylpPBlY5ef0HdOuQhs5n4PNAC7AeuBPd8qeh8hm4G10HMowu+b3bz3wFVjjX72XgO6Q1OMj2syEmLBaLxXBMcQ1ZLBaLJQfWEFgsFovhWENgsVgshmMNgcVisRiONQQWi8ViONYQWCwlICIfFpFJ1U6HxeIntvmoxVICTu/mFUqpSLXTYrH4hS0RWCw5EJHJIvJnEVnrxMf/HDoGziMi8oizzetE5GkReV5EfuPEgEJE2kXkVicu/LMicqSz/HLnWGtF5PHqqbNYklhDYLHkZiXQqZQ6SSl1PDoCaifwaqXUq0VkNvBp4Dyl1KnoXsAf9ezfq5Q6Ad2781vOss8CFyilTgIuqYwMiyU/1hBYLLlZB5wvIl8VkbOVUr1p61+BHgTlSRF5AR0jZqFn/d2e/zOc6SeBO0TkPegBkyyWqtNceBOLxUyUUlucoQEvAr4oIg+nbSLAQ0qpK3MdIn1aKfV+ETkdeD2wWkSWK6V2+512i6UUbInAYsmBiMwDYkqpu4CvocNA96OHCAX4F3Cmx/8/WUSWeg7xFs//0842RyilnlFKfRY98Iw3lLDFUhVsicBiyc0JwNdE5AA6UuQH0C6eB0Sk06knuAa4W0TGO/t8Gh3lFmCmiLwIDKKHDMQ53lHo0sTD6LF1LZaqYpuPWiwBYJuZWuoJ6xqyWCwWw7ElAovFYjEcWyKwWCwWw7GGwGKxWAzHGgKLxWIxHGsILBaLxXCsIbBYLBbD+f/FJ8DcW9AHQAAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Based on the training curve, it can be observed that the training loss in both TextMLP models gradually decreases and ultimately converges at a stable value. Thus, it can be concluded that the binary text classifier has achieved a stable stage. Generally, the model with a pretrained embedding layer converges faster using fewer steps, while the one with an unpretrained embedding layer requires less time to train due to its fewer parameters.\n","\n","However, it should be noted that the model's performance is affected by the split of the training and test dataset. Changing the \"seed\" of load_data() can cause the training accuracy to fluctuate. In some cases, the test accuracy even appears to be higher than the training accuracy, which may be attributed to the simple filling strategy of NaN values in the raw tabular. In other words, the filled dataframe is still uneven, indicating that designing better filling strategies for NaN values could be a promising direction for improvements."],"metadata":{"id":"E_S_bp4MAcBc"},"id":"E_S_bp4MAcBc"},{"cell_type":"code","source":[],"metadata":{"id":"p_nmjDKbqAVG"},"id":"p_nmjDKbqAVG","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[{"file_id":"1pyu8anAxyitbrjfPJK4RsA11_1aWCS4N","timestamp":1679745651391}]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"28ad201284324f6fa69e8f46fd57d802":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_991f5c7261b2494ca2dc05c0390b0200","IPY_MODEL_c9bbc221830542fd804677e1afd4eaf6","IPY_MODEL_83b5afa9302445c185837ef6a3f07542"],"layout":"IPY_MODEL_b8360569f16a4440acebbe18b1f2da32"}},"991f5c7261b2494ca2dc05c0390b0200":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_390e0b617dae4af79c6408d7ffa673a5","placeholder":"​","style":"IPY_MODEL_ebbe0cd202d344c18991a586862c42c7","value":"Downloading (…)lve/main/config.json: 100%"}},"c9bbc221830542fd804677e1afd4eaf6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1df077a23b404fa6ae71445a9ab455ec","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8956c247e4b4d3c88d4c124a3c19f02","value":570}},"83b5afa9302445c185837ef6a3f07542":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1593e5cb3193447b879f318b4561e40b","placeholder":"​","style":"IPY_MODEL_e14654f94dfe44dabce02f41090d91e1","value":" 570/570 [00:00&lt;00:00, 23.7kB/s]"}},"b8360569f16a4440acebbe18b1f2da32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"390e0b617dae4af79c6408d7ffa673a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebbe0cd202d344c18991a586862c42c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1df077a23b404fa6ae71445a9ab455ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8956c247e4b4d3c88d4c124a3c19f02":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1593e5cb3193447b879f318b4561e40b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e14654f94dfe44dabce02f41090d91e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b43b0890d2b4bfb94689fe5f5b808b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_565a9f11608a48469b8dc0a2a00212ee","IPY_MODEL_b751710fd3ff4859a606b96cbd5e7059","IPY_MODEL_812845833d1a494082c14244d69936e8"],"layout":"IPY_MODEL_91624053f30a445f93efc2a6527d6aa8"}},"565a9f11608a48469b8dc0a2a00212ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3481edac68af489ba70db25d421a8d4f","placeholder":"​","style":"IPY_MODEL_fa407a9110bb473796710abe77c9bf0f","value":"Downloading pytorch_model.bin: 100%"}},"b751710fd3ff4859a606b96cbd5e7059":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9438945058f84e78abbee93539f634a2","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f66c1c0121f43b2bffc161ffd5cc87e","value":440473133}},"812845833d1a494082c14244d69936e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2764ee4760946168db9e585dccc1f9e","placeholder":"​","style":"IPY_MODEL_6ab3f5796e5d4489b0c785b23659fa41","value":" 440M/440M [00:02&lt;00:00, 165MB/s]"}},"91624053f30a445f93efc2a6527d6aa8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3481edac68af489ba70db25d421a8d4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa407a9110bb473796710abe77c9bf0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9438945058f84e78abbee93539f634a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f66c1c0121f43b2bffc161ffd5cc87e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b2764ee4760946168db9e585dccc1f9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ab3f5796e5d4489b0c785b23659fa41":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}